\chapter{Algebra}
We gave an introduction to the basic computational skills needed for a pen \& paper approach to SNARKS in the previous chapter. In this chapter we get a bit more abstract and clarify a lot of mathematical terminology and jargon.

When you read papers about cryptography or mathematical papers in general, you will frequently stumble across algebraic terms like \textit{groups}, \textit{fields},\textit{rings} and similar. To understand what is going on, it is necessary to get at least some understanding of these terms. In this chapter we therefore with a short introduction to those terms.

In a nutshell, algebraic types like groups or fields define sets that are analog to numbers to various extend, in the sense that you can add, subtract, multiply or divide on thoses sets. 

We know many example of sets that fall under those categories, like the natural numbers, the integers, the ratinal or the real numbers. they are in some sense already the most fundamental examples.

\section{Groups} Groups are abstractions that capture the essence of mathematical phenomena, like addition and subtraction, multiplication and division, permutations, or symmetries.

To understand groups, remember back in school when we learned about addition and subtraction of integers (Forgetting about integer multiplication for a moment). We learned that we can always add two integers and that the result is guranteed to be an integer again. We also learned how to deal wih brackets, that nothing happens, when we add zero to any integer, that it doesn't matter in which order we add a given set of integers and that for every integer there is always another integer (the negative), such that when we add both together we get zero. 

These conditions are the defining properties of a group and mathematicians have recognozed that the exact same set of rules can be found in very different mathematical structures. It therefore makes sense to give a formulation of what a group should be, detached from any concrete example. This allows one to handle entities of very different mathematical origins in a flexible way, while retaining essential structural aspects of many objects in abstract algebra and beyond. 

Distilling these rules to the smallest independend list of properties and making them abstract we arrive at the definition of a group:

A \textbf{group} $(\G,\cdot) $ is a set $ \G$, together with a map $ \cdot: \G \times \G \to \G $, called the group law, such that the following properties hold:
\begin{itemize}
\item (Existence of a neutral element) There is a $e\in\G$ for all $g\in\G$, such that $e\cdot g=g$ as well as $g\cdot e = g$.
\item (Existence of an inverse) For every $g\in\G$ there is a $g^{-1}\in\G$, such that $g\cdot g^{-1}=e$ as well as $g^{-1}\cdot g = e$.
\item (Associativity) For every $g_1,g_2,g_3\in\G$ the equation 
$g_1\cdot(g_2\cdot g_3) = (g_1\cdot g_2)\cdot g_3$ holds.
\end{itemize}
Rephrasing the abstract definition in more laymans terms, a group is something, where we can do computations that resembles the behaviour of addition of integers. Therefore when the reader reads the term group they are adviced to think of something where can combine some element with another element into a new element in a way that is reversable and where the order of combining many elements doesn't matter.
\begin{notation}
Let $(\mathbb{G}\cdot)$ be a finite group. If there is no risk of ambigously we frquently drop the symbol $\cdot$ and simply write $\mathbb{G}$ as a notation for the group keeping the group law implicit.
\end{notation}
As we will see in what follows, groups are all over the place in cryptography and in SNARKS. In particular we will see in XXX, that the set of points on an elliptic curve define a group, which is the most important example in this book. To give some more familiar examples first:
\begin{example}[Integer Addition and Subtraction]
The set $(\Z,+)$ of integers together with integer addition is the archetypical example of a group, where the group law is traditionally written as $+$ (instead of $\cdot$). To compare integer addition against the abstract axioms of a group, we first see that the neutral element $e$ is the number $0$, since $a+0=a$ for all integers $a\in $ and that the inverse of a number is the negative, since $a+(-a)=0$, for all $a\in\Z$. In addition we know that $(a+b)+c=a+(b+c)$, so integers with addition are indeed a group in the abstract sense.
\end{example}
\begin{example}[The trivial group]
The most basic example of a group, is group with just one element $\{\bullet\}$ and the group law $\bullet\cdot \bullet=\bullet$. 
\end{example}
%\begin{example}[Rotations]
%To give an example of a group that has effects in the real world, consider a dice. Then our group is the set of all possible ways to rotate the dice by 90 degrees alonng an imagined axix through two opposite faces. The group law is composition of rotations. So say hold the dice with two fingers at $1$ and $6$. $1$ is the face that points towards you and $5$ is the top face. Then you first rotate the dice along the $1$-$6$ axix by 90 degrees clockwise, such that now $3$ is the top face. Then you hold the dice at $5$ and 
%\end{example}
\paragraph{Commutative Groups} When we look at the general definition of a group we see that it is somewhat different from what we know from integers. For integers we know, that it doesnt matter in which order we add two integers, as for example $4+2$ is the same as $2+4$. However we also know from example XXX, that this is not always the case in groups. 

To capture the special case of a group where the order in which the group law is executed doesn't matter, the concept of so called a \textbf{commutative group} is introduced. To be more precise a group is called commutative if  $g_1\cdot g_2 = g_2 \cdot g_1$ holds for all $g_1,g_2\in\G$. 
\begin{notation}
In case $(\G,\cdot)$ is a commutative group, we frequently use the so called \textit{additive notation} $(\G,+)$, that is we write $+$ instead of $\cdot$ for the group law and $-g:=g^{-1}$ for the inverse of an element $g\in\G$.
\end{notation}
\begin{example} Consider the group of integers with integer addition again.
Since $a+b=b+a$ for all integers, this group is the archetypical example of a commutative group. Since there are infinite many integers, $(\Z,+)$ is not a finite group.
\end{example}
\begin{example} Consider our definition of modulo $6$ residue classes $(\Z_6,+)$ as defined in the addition table from example XXX. As we see the residue class $0$ is the neutral element in modulo $6$ arithmetics and the inverse of a residue class $r$ is given by $6-r$, since $r+(6-r)=6$, which is congruent to $0$, since $\Zmod{6}{6}=0$. Moreover $(r_1+r_2)+r_3=r_1+(r_2+r_3)$ is inherited from integer arithmetic.  

We therefore see that $(\Z_6,+)$ is a group and since addition table XX is symmetric, we see $r_1+r_2 = r_2+r_1$ which shows that $(\Z_6,+)$ is commutative. 
\end{example}
The previous example provided us with an important example of commuative groups that are important in this book. Abstracting from this example and considering residue classes $(\Z_n,+)$ for arbitrary moduli $n$, it can be shown that $(\Z,+)$ is a commutative group with neutral element $0$ and additive inverse $n-r$ for any element $r\in\Z_n$. We call such a group the \textit{reminder class groups} of modulus $n$.

Of particular importance for pairing based cryptography in general and snarks in particular are so called \textit{pairing maps} on commutative groups. To be more precise let $\G_1$, $\G_2$ and $\G_3$ be three commutative groups. For historical reasons, we write the group law on $\G_1$ and $\G_2$ in additive notation and the group law on $\G_3$ in multiplicative notation. Then a \textbf{pairing map} is a function
\begin{equation}
e(\cdot,\cdot): \G_1 \times \G_2 \to \G_3
\end{equation}
that takes pairs $(g_1,g_2)$ (products) of elements from $\G_1$ and $\G_2$ and maps them somehow to elements from $\G_3$, such that the \textit{bilinearity} property holds: For all $g_1,g_1'\in \G_1$ and $g_2\in \G_2$ we have $e(g_1+ g_1',g_2)= e(g_1,g_2)\cdot e(g_1',g_2)$ and for all $g_1\in \G_1$ and $g_2, g_2'\in \G_2$ we have $e(g_1,g_2+ g_2')= e(g_1,g_2)\cdot e(g_1,g_2')$. 

A pairing map is called \textit{non-degenerated}, if whenever the result of the pairing is the neutral element in $\G_3$, one of the input values must be the neutral element of $\G_1$ or $\G_2$. To be more precise $e(g_1,g_2)=e_{\G_3}$ implies $g_1=e_{\G_1}$ or $g_2=e_{\G_2}$.

So roughly speaking bilinearity means, that it doesn't matter if we first execute the group law on any side and then apply the bilinear map of if we first applay the bilinear map and then apply the group law. Moreover non-degeneray means that the result of the pairing is zero, only if at least one of the input values is zero.
\begin{example}Maybe the most basic example of a non-degenerate pairing is optained, if we take $\G_1$, $\G_2$ and $\G_3$ all to be the group of integers with addition $(\Z,+)$. Then the following map 
$$
e(\cdot,\cdot): \Z \times \Z \to \Z \; (a,b)\mapsto a\cdot b
$$
defines aa non-degenerate pairing. To see that observe, that bilinearity follows from the distriutive law of integers, since for $a,b,c\in \Z$, we have $e(a+b,c)=(a+b)\cdot c = a\cdot c + b\cdot c = e(a,c)+ e(b,c)$ and the same reasoning is true for the second argument.

To the that $e(\cdot,\cdot)$ is non degenrate, assume that $e(a,b)=0$. Then a$\cdot b =0$ and this implies that $a$ or $b$ must be zero.
\end{example} 

\begin{exercise} Consider example XXX again and let $\F_5^*$ be the set of all remainder classes from $\F_5$ without the class $0$. Then $\F_5^*=\{1,2,3,4\}$. Show that $(\F_5^*,\cdot)$ is a commutative group. 
\end{exercise}
\begin{exercise} Generalizing the previous exercise, consider general moduli $n$ and let $\Z_n^*$ be the set of all remainder classes from $\Z_n$ without the class $0$. Then $\Z_n^*=\{1,2,\ldots,n-1\}$. Give a counter example to show that $(\Z^*_n,\cdot)$ is not a group in general. 

Find a condition, such that $(\Z^*_n,\cdot)$ is a commutative group, compute the neutral element, give a closed form for the inverse of any element and proof the commutative group axioms.
\end{exercise}
\begin{exercise} Consider the remainder class groups $(\Z_n,+)$ for some modulus $n$. Show that the map
$$
e(\cdot,\cdot): \Z_n \times \Z_n \to \Z_n \; (a,b)\mapsto a\cdot b
$$
is bilinear. Why is it not a pairing in general and what condition must be imposed on $n$, such that the map is a pairing?
\end{exercise}
\paragraph{Finite groups} As we have seen in the previous examples, groups can either contain infinite many elements (as the integers) or finitely many elements as for example the remainder class groups $(\Z_n,+)$. To capture this distinction a group is called a \textit{finite group}, if the underlying set of elements is finite. In that case the number of elements of that group is called its \textbf{order}.
\begin{notation}
Let $\mathbb{G}$ be a finite group. Then we frquently write $ord(\mathbb{G})$ or  $|\mathbb{G}|$ for the order of $\mathbb{G}$.
\end{notation}
\begin{example}
Consider the remainder class groups $(\Z_6,+)$ and $(\F_5,+)$ from example XXX and example XXX and the group $(\F_5^*,\cdot)$ from exercise XX. We can easily see that the order of $(\Z_6,+)$ is $6$, the order of $(\F_5,+)$ is five and the order of $(\F_5^*,\cdot)$ is $4$.

To be more general, considering arbitrary moduli $n$, then we know from Euklidean division, that the order of the remainder class group $(\Z_n,+)$ is $n$. 
\end{example}
\begin{exercise}The RSA crypto system is based on a modulus $n$ that is typically the product of two prime numbers of size $2048$-bits. What is (approximately) the order of the rainder class group $(\Z_n,+)$ in this case? 
\end{exercise}
\paragraph{Generators} Of special interest, when working with groups are sets of elements that can generate the entire group, by applying the group law repeadly to those elements or their inverses only. 

Of course every group $\G$ has trivially a set of generators, when we just consider every element of the group to be in the generator set. So the more interesting question is to find the smallest set of generators. Of particular interest in this regard are groups that have a single generator, that is there exist an element $g\in\G$, such that every other element from $\G$ can be computed by repeated combination of $g$ and its inverse $g^{-1}$ only. Those groups are called \textbf{cyclic groups}.
\begin{example} The most basic example of a cyclic group are the integers $(\Z,+)$ with integer addition. To see that observe that $1$ is a generator of $\Z$, since every integer can be obtained by repeadly add either $1$ or its inverse $-1$ to itself. For example 
$-4$ is generated by $-1$, since $-4=-1+(-1)+(-1)+(-1)$. 
\end{example}
\begin{example} Consider a modulus $n$ and the remainder class groups $(\Z_n,+)$ from example XXX. These groups are cyclic, with generator $1$, since every other element of that group can be constructed by repeadly adding the remainder class $1$ to itself. Since $\Z_n$ is also finite, we know that $(\Z_n,+)$ is a finite cyclic group of order $n$.
\end{example}
\begin{example} Let $p\in\P$ be prime number and $(\F_p^*,\cdot)$ the finite group from exercise XXX. Then $(\F_p^*,\cdot)$ is cyclic and every element $g\in\F_q^*$ is a generator. 
\end{example}
\paragraph{The discrete Logarithm problem}
In cryptography in general and in snark development in particular, we often do computations "in the exponent" of a generator. To see what this means, observe, that when 
$\G$ is a cyclic group of order $n$ and $g\in \G$ is a generator of $\G$, then there is a map, called the \textbf{exponential map} with respect to the generator $g$
\begin{equation}
g^{(\cdot)}: \Z_n \to \G\; x \mapsto g^x
\end{equation}
where $g^x$ means "multiply $g$ $x$-times by itself and $g^0=e_{\G}$. This map has the remarkable property maps the additive group law of the remainder class group $(\Z_n,+)$ in a one-to-one correspondence to the group law of $\G$. 

To see that first observe, that since $g^0:=e_{\G}$ by definition, the neutral element of $\Z_n$ is mapped to the neutral element of $\G$ and since $g^{x+y}=g^x\cdot g^y$, the map respects the group laws. 

Since the exponential map respects the group law, it doesn't matter if we do our computation in $\Z_n$ before we write the result into the exponent of $g$ or afterwards. The result will be the same. This is what is usually meant by saying we do our computations "in the exponent".
\begin{example} Consider the multiplicative group $(\F_{5}^*,\cdot)$ from example XXX. We know that $\F_{5}^*$ is a cyclic group of order $4$ and that every element is a generator. Choose $3\in\F_5^*$, we then know that the map
$$
3^{(\cdot)}: \Z_4 \to \F_5^* \; x \mapsto 3^x
$$
respects the group law of addition in $\Z_4$ and the group law of multiplication in $\F_5^*$.
And indeed doing a computation like 
\begin{align*}
3^{2+3-2} &=3^{3}\\
          & = 2
\end{align*}
in the exponent gives the same result as doing the same computation in $\F*_5$, that is 
\begin{align*}
3^{2+3-2} &= 3^2 \cdot 3^3 \cdot 3^{-2}\\
          &= 4\cdot 2 \cdot (-3)^2\\
          &= 3\cdot 2^2\\
          &= 3\cdot 4 \\
          &= 2
\end{align*}
\end{example}
Since the exponential map is a one-to-one correspondence, that respects the group law, it can be shown that this map has an inverse
\begin{equation}
log_g(\cdot): \G \to \Z_n\; x \mapsto log_g(x)
\end{equation}
which is called the \textbf{discrete logarithm} map with respect to the base $g$. Discrete logarithms are highly importsnt in cryptography as there are groups, such that the exponential map and its inverse the discrete logarithm, are believed to be one way functions, that is while it is possible to compute the exponential map in polynomial time, computing the discrete log takes (sub)-exponential time. 

Now consider a finite cyclic group $\G$ of order $n$ and a generator $g$ of $\G$. The \textbf{discrete logarithm problem} is then the task, to find a solution $x\in\Z_n$, to the equation 
\begin{equation}
h = g^x
\end{equation}
for some given $h\in\G$. In groups where the expontial map and the discrete logarithm map are believed to be examples of one way functions, it is computationally hard to find solutions to this equation.
\section{Commutative Rings}
Thinking of integers again, we know, that there are actually two operations addition and multiplication and as we know addition defines a group structure on the set of integers. However multiplication does not define a group structure as we know that integers in general don't have multiplicative inverses. 

Combinations like this are captured by the concept of a so called \textit{commutative ring with unit}. To be more precise, a commutative ring with unit $ (R, +, \cdot, 1) $ is a set $R$, provided with two maps $ +: R \cdot R \to R $ and $ \cdot: R \cdot R \to R $, called \textit{addition} and \textit{multiplication}, such that the following conditions hold:
\begin{itemize}
\item $ \left (R, + \right) $ is a commutative group, where the neutral element is denoted  with $ 0 $.
\item (Commuativity of the multiplication) We have $r_1\cdot r_2 = r_2\cdot r_1$ for all $r_1, r_2\in R$. 
\item (Existence of a unit) There is an element $1\in R$, such that $1\cdot g$ holds for all $g\in R$, 
\item (Associativity) For every $g_1,g_2,g_3\in\G$ the equation 
$g_1\cdot(g_2\cdot g_3) = (g_1\cdot g_2)\cdot g_3$ holds. 
\item (Distributivity) For all $ g_1, g_2, g_3 \in R $ the distributive laws
$ g_1 \cdot \left (g_2 + g_3 \right) = g_1 \cdot g_2 + g_1 \cdot g_3$ holds.
\end{itemize}
\begin{example}[The Ring of Integers] The set $\Z$ of integers with the usual addition and multiplication is the archetypical example of a commutative ring with unit $1$. 
\end{example}
\begin{example}[Underlying commutative group of a ring] Every commutative ring with unit $(R,+,\cdot,1)$ gives rise to group, if we just forget about the multiplication
\end{example}
The following example is more interesting. The motivated reader is encuraged to think through this example, not so much because we need this in what follows, but more so as it helps to detach the reader from familiar styles of computation. 
\begin{example} Let $S:=\{\bullet,\star,\odot,\otimes\}$ be a set that contains four elements and let adiition and multiplication on $S$ be defined as follows:
\begin{center}
  \begin{tabular}{c | c c c c c c}
    $\cup$ & $\bullet$ & $\star$ & $\odot$ & $\otimes$ \\\hline
    $\bullet$ & $\bullet$ & $\star$ & $\odot$ & $\otimes$ \\
    $\star$ & $\star$ & $\odot$ & $\otimes$ & $\bullet$ \\
    $\odot$ & $\odot$ & $\otimes$ & $\bullet$ & $\star$ \\
    $\otimes$ & $\otimes$ & $\bullet$ & $\star$ & $\odot$ \\
  \end{tabular} \quad \quad \quad \quad
  \begin{tabular}{c | c c c c c c}
$ \circ $ & $\bullet$ & $\star$ & $\odot$ & $\otimes$ & \\\hline
        $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ &\\
        $\star$ & $\bullet$ & $\star$ & $\odot$ & $\otimes$ &\\
        $\odot$ & $\bullet$ & $\odot$ & $\bullet$ & $\odot$ &\\
        $\otimes$ & $\bullet$ & $\otimes$ & $\odot$ & $\star$ &\\
  \end{tabular}
\end{center}
Then $(S,\cup,\circ)$ is a ring with unit $\star$ and zero $\bullet$. It therefore makes sense to ask for solutions to equations like this one:
Find $x\in S$ such that
$$
\otimes \circ (x \cup \odot ) = \star
$$
To see how such a "moonmath equation" can be solved, we have to keep in mind, that rings behaves mostly like normal number when it comes to bracketing and computation rules. The only differences are the symbols and the actual way to add and multiply. With this we solve the equation for $x$ in the "usual way"
\begin{align*}
\otimes \circ (x \cup \odot ) &= \star & \text{ \# aplly the distributive law}\\
\otimes \circ x \cup \otimes \circ \odot  &= \star &\# \otimes \circ \odot = \odot\\
\otimes \circ x \cup \odot  &= \star & \text{\# concatenate the $\cup$ inverse of $\odot$ to both sides}\\
\otimes \circ x \cup \odot \cup -\odot  &= \star \cup -\odot & \# \odot \cup -\odot = \bullet\\
\otimes \circ x \cup \bullet &= \star \cup -\odot & \text{\# $\bullet$ is the $\cup$ neutral element}\\
\otimes \circ x &= \star \cup -\odot & \text{\# for $\cup$ we have $-\odot = \odot$} \\
\otimes \circ x &= \star \cup \odot &\# \star \cup \odot = \otimes \\
\otimes \circ x &= \otimes  &\text{\# concatenate the $\circ$ inverse of $\otimes$ to both sides}\\
(\otimes)^{-1}\circ \otimes \circ x &= (\otimes)^{-1}\circ \otimes & \text{\# multiply with the multiplicative inverse}\\
\star \circ x &= \star\\
x &= \star
\end{align*}
So even despite this equation looked really alien on the surface, computation was basically exactly the way "normal" equation like for fractional numbers are done.

Note however that in a ring, things can be very different, then most are used to, whenever a multiplicative inverse would be needed to solve an equation in the usual way. For example the equation
$$
\odot \circ x = \otimes
$$
can not be solved for $x$ in the usual way, since there is no multiplicative inverse for $\odot$ in our ring. And in fact looking at the multiplication table we see that no such $x$ exits. On another example the equation
$$
\odot \circ x = \odot
$$
can has not a single solution but two $x\in\{\star, \otimes\}$. Having no or two solutions is certainly not something to expect from types like $\mathbb{Q}$. 
\end{example}
\begin{example} Considering polynomials again, we note from their definition, that what we have called the type $R$ of the coefficients, must in fact be a commutative ring with unit, since we need addition, multiplication, commutativity and the existence of a unit for $R[x]$ to have the properties we expect. 

Now considering $R$ to be a ring, addition and multiplication of polynomials as defined in XXX, actually makes $R[x]$ into a commutative ring with unit, too, where the polynomial $1$ is the multiplicative unit.
\end{example}
\begin{example} Let $n$ be a modulus and $(\Z_n,+,\cdot)$ the set of all remainder classes of integers modulo $n$, with the projection of integer addition and multiplication as defined in XXX. It can be shown that $(\Z_n,+,\cdot)$ is a commutative ring with unit $1$.
\end{example}
Considering the exponential map from XXX again, let $\G$ be a finite cyclic group of order $n$ with generator $g\in\G$. Then the ring structure of $(\Z_n,+,\cdot)$ is mapped onto the group structure of $\G$ in the following way:
\begin{align*}
g^{x+y} &= g^x\cdot g^y & \text{for all } x,y\in\Z_n\\
g^{x\cdot y} &= \left( g^x\right)^y & \text{for all } x,y\in\Z_n
\end{align*}
This of particular interest in cryptographic and snarks, as it allows for the evaluation of polynomials with coefficients in $\Z_n$ to be evaluated "in the exponent". To be more precise let $p\in \Z_n[x]$ be a polyninomial with $p(x)=a_m\cdot x^m+a_{m-1}x^{m-1}+\ldots + a_1x +a_0$. Then the previously defined exponential laws XXX imply that
\begin{align*}
g^{p(x)} & = g^{a_m\cdot x^m+a_{m-1}x^{m-1}+\ldots + a_1x +a_0}\\
         & = \left(g^{x^m}\right)^{a_m}\cdot \left(g^{x^{m-1}}\right)^{a_{m-1}}\cdot \ldots\cdot \left(g^{x}\right)^{a_1}\cdot g^{a_0}
\end{align*}
and hence to evaluate $p$ at some point $s$ in the exponent, we can insert $s$ into the right hand side of the last equation and evaluate the product.
 
As we will see this is a key insight to understand many snark protocols like e.g. Groth16 or XXX.
\begin{example} To give an example for the evaluation of a polynomial in the exponent of a finite cyclic group, xonsider the exponential map 
$$
3^{(\cdot)}: \Z_4 \to \F_5^* \; x \mapsto 3^x
$$
from example XXX. Choosing the polynomial $p(x)= 2x^2 +3x +1$ from $\Z_4[x]$, we can evaluate the polynomial at say $x=2$ in the exponent of $3$ in two different ways. On the one hand side we can evaluate $p$ at $2$ and then write the result into the expinent, which gives
\begin{align*}
3^{p(2)} &=3^{2\cdot 2^2+3\cdot 2 +1}\\
          & = 3^{2\cdot 0 +2 +1}\\
          & = 3^{3}\\
          & = 2
\end{align*}
and on the other hand we can use the right hand side of equation to evaluate $p$ at $2$ in the exponent of $3$, which gives: 
\begin{align*}
3^{p(2)} &= \left(3^{2^2}\right)^2 \cdot \left(3^{2}\right)^3\cdot 3^1\\
         &= \left(3^{0}\right)^2 \cdot 3^3\cdot 3\\
         &= 1^2 \cdot 2 \cdot 3\\
         &= 2 \cdot 3\\
         &= 2
\end{align*}
\end{example}

\section{Fields}
In this chapter we started with the definition of a group, which we the expended into the definition of a commutative ring with unit. Those rings generalize the behaviour of integers. In this section we will look at the special case of commutative rings, where every element, other then the neutral element of addition, has a multiplicative inverse. Those structures behave very much like the rational numbers $\mathbb{Q}$, which are in a sense an extension of the ring of integers, that is constructed by just including newly defined multiplicative inverses (the fractions) to the integers. 

Now considering the definition of a ring XXX again, we define a \textbf{field} $ (\F, +, \cdot) $ to be a set $ \F$, together with two maps $ +: \F \cdot \F \to \F $ and $ \cdot: \F \cdot \F \to \F $, called \textit{addition} and \textit{multiplication}, such that the following conditions holds
\begin{itemize}
\item $ \left (\F, + \right) $ is a commutative group, where the neutral element is denoted by $ 0 $.
\item $ \left (\F \setminus \left \{0 \right \}, \cdot \right) $ is a commutative group, where the neutral element is denoted by $ 1 $.
\item (Distributivity) For all $ g_1, g_2, g_3 \in \F $ the distributive law
$g_1 \cdot \left (g_2 + g_3 \right) = g_1 \cdot g_2 + g_1 \cdot g_3$ holds.
\end{itemize}
If a field is iven and the definition of its addition and multiplication is not ambiguous, we will often simple write $\F$ instead of $(\F,+,\cdot)$ to describe it. We moreover write $\F^*$ to describe the multiplicative group of the field, that is the set of elements, except the neutral element of addition, with the multiplication as group law.

The \textbf{characteristic} $char(\F)$ of a field $ \F $ is the smallest natural number $ n \geq 1 $, for which the $ n $ -fold sum of $ 1 $ equals zero, i.e. for which $ \sum_{i = 1} ^ n 1 = 0 $. If such a $ n> 0 $ exists, the field is also called to have a \textit{finite characteristic}. If, on the other hand, every finite sum of $1$ is not equal to zero, then the field is defined to have characteristic $ 0 $.
\begin{example}[Field of rational numbers] Probably the best known example of a field is the set of rational numbers $\mathbb{Q}$ together with the usual definition of addition, subtraction, multiplication and division. Since there is no counting number $n\in \N$, such that $\sum_{j=0}^n 1 =0$ in the rational numers, the characteristic $char(\mathbb{Q})$ of the field $\mathbb{Q}$ is zero. In sage rational numbers are called like this
\begin{sagecommandline}
sage: QQ
sage: QQ(1/5) # Get an element from the field of rational numbers
sage: QQ(1/5) / QQ(3) # Division
\end{sagecommandline}
\end{example}
\begin{example}[Field with two elements] It can be shown that in any field, the neutral element $0$ of addition must be different from the neutral element $1$ of multiplication, that is we always have $0\neq 1$ in a field. From this follows that the smallest field must contain at least two elements and as the following addition and multiplication tables show, there is indeed a field with two elements, which is usually called $\F_2$:

Let $\F_2:=\{0,1 \}$ be a set that contains two elements and let addition and multiplication on $\F_2$ be defined as follows:
\begin{center}
  \begin{tabular}{c | c c c}
    + & 0 & 1 \\\hline
    0 & 0 & 1\\
    1 & 1 & 0 \\
  \end{tabular} \quad \quad \quad \quad
  \begin{tabular}{c | c c c}
$\cdot$ & 0 & 1 \\\hline
      0 & 0 & 0 \\
      1 & 0 & 1 \\
  \end{tabular}
\end{center}
Since $1+1=0$ in the field $\F_2$, we know that the characteristic of $\F_2$ is there, that is we have $char(\F_2)=0$.

For reasons we will understand better in XXX, sage defines this field as a so called Galois field with 2 elements. It is called like this:
\begin{sagecommandline}
sage: F2 = GF(2)
sage: F2(1) # Get an element from GF(2)
sage: F2(1) + F2(1) # Addition
sage: F2(1) / F2(1) # Division
\end{sagecommandline}
\end{example}
\begin{example}
Both the real numbers $\mathbb{R}$ as well as the complex numbers $\mathbb{C}$ are well known examples of fields.
\end{example}
\begin{exercise}
Consider our remainder class ring $(\F_5,+,\cdot)$ and show that it is a field. What is the characteristic of $\F_5$?
\end{exercise}
\paragraph{Prime fields}
As we have seen in the variou examples of the previous sections, modular arithmetics behaves in many ways similar to ordinary arithmetics of integers, which is due to the fact that remainder class sets $\Z_n$ are commutative rings with units.

However at the same time we have seen in XXX, that, whenever the modulus is a prime number, every remainder class other then the zero class, has a modular multiplicative inverse. This is an important observation, since it immediately implies, that in case of a prime number, the modulus $\Z_n$ is not just a ring but actually a \textit{field}. Moreover since $\sum_{j=0}^n 1 = 0$ in $\Z_n$, we know that those fields have finite characteristic $n$ 

To distinguish this important case from arbitrary reminder class rings, we write  $ (\F_p, +, \cdot) $ for the field of all remainder classes for a prime number modulus $p \in \Prim$ and call it the \textbf{prime field} of characteristic $p$.

Prime fields are the foundation for many of the contemporary algebra based cryptographic systems, as they have many desireable properties. One of them is, that since these sets are finite and a prime field of characteristic $p$ can be represented on a computer in roughly $log_2(p)$ amount of space, no precision problems occure, that are for example unavoidable for computer representations of rational numbers or even the integers.

Since prime fields are special cases of remainder class rings, all computations remain the same. Addition and multiplication can be computed by first doing normal integer addition and multiplication and then take the remainder modulus $p$. Subtraction and division can be computed by addition or multiplication with the additive or the multiplicative inverse, respectively. The additive inverse $-x$ of a field element $x\in\F_p$ is given by $p-x$ and the multiplicative inverse of $x\neq 0$ is given by $x^{p-2}$, or can be computed using the extended Euclidean algorithm. 

Note however that these computations might not be the fastest to implement on a computer. They are however useful in this book as they are easy to compute for small prime numbers.
\begin{example}
The smallest field is the field $\F_2$ of characteristic $2$ as we have seen it in example XXX. It is the prime field of the prime number $2$.
\end{example}
\begin{example}
To summarize the basic aspects of computation in prime fields, lets consider the prime field $\F_5$ and simplify the following expression 
$$\left(\frac{2}{3} - 2\right)\cdot 2 $$
A first thing to note is that since $\F_5$ is a field all rules like bracketing (distributivity), summing ect. are identical to the rules we learned in school when we where dealing with rational, real or complex numbers. We get
\begin{align*}
\left(\frac{2}{3} - 2\right)\cdot 2 &= 
 \frac{2}{3}\cdot 2 - 2\cdot 2 & \text{\# distributive law}\\
 &= \frac{2\cdot 2}{3} - 2\cdot 2 & \Zmod{4}{5}=4 \\
 &= \frac{4}{3} - 4 & \text{\# multiplicative inverse of 3 is } \Zmod{3^{5-2}}{5}=2\\
 &= 4\cdot 2 - 4 & \text{\# additive inverse of 4 is } 5-4=1\\
 &= 4\cdot 2 +1 & \Zmod{8}{5}=3\\
 &= 3 +1 & \Zmod{4}{5}=4\\
 &= 4
\end{align*}
In this computation we computed the multiplicative inverse of $3$ using the identity
$x^{-1}=x^{p-2}$ in a prime field. This impractical for large prime numbers. Recall that another way of computing the multiplicative inverse is the Extended Euclidean algorithm.  To see that again, the task is to compute $x^{-1}\cdot 3 + t \cdot 5 =1$, but $t$ is actulally irrelevant. We get
\begin{center}
  \begin{tabular}{c | c c l}
    k & $ r_k $ & $ x^{-1}_k $ & $ t_k = \Zdiv{(r_k-s_k \cdot a)}{b} $ \\\hline
    0 & 3 & 1 & $\cdot$\ \\
    1 & 5 & 0 & $\cdot$ \\
    2 & 3 & 1 & $\cdot$ \\
    3 & 2 &-1 & $\cdot$ \\
    4 & 1 & 2  & $\cdot$ \\
  \end{tabular}
\end{center}
So the multiplicative inverse of $3$ in $\Z_5$ is $2$ and indeed if compute $3\cdot 2$ we get $1$ in $\F_5$. 
\end{example}
\paragraph{Square Roots}
In this part we deal with square numbers also called \textit{quadratic residues} and \textit{square roots} in prime fields. This is of particular importance in our studies on elliptic curves as only square numbers can actually be points on an elliptic curve. 

To make the intuition of quadratic risidues and roots precise, let $p \in \Prim $ be a prime number and $\F_p $ its associate prime field. Then a number $x\in \F_p$ is called a \textbf{square root} of another number $y\in\F_p$, if $x$ is a solution to the equation
\begin{equation}
x^2 = y
\end{equation}
In this case $y$ is called a \textbf{quadratic residue}. On the other hand, if $y$ is given and the quadratic equation has no $x$ solution, we call $ y $ as \textbf{quadratic non-residue}. For any $ y \in \F_p $ we write
\begin{equation}
\sqrt{y}: = \{x \in \F_p \; | \; x^2 = y \}
\end{equation}
for the set of all square roots of $ y $ in the prime field $ \F_n $. (If $ y $ is a quadratic non-residue, then $ \sqrt{y} = \emptyset $ and if $ y = 0 $, then $ \sqrt{y} = \{0 \} $)

So roughly speaking, quadratic residues are numbers such that we can take the square root from them and quadratic non-residues are numbers that don't have square roots. The situation therefore parallels the know case of integers, where some integers like $4$ or $9$ have square roots and others like $2$ or $3$ don't (as integers).

It can be shown that in any prime field every non zero element has either no square root or two of them. We adopt the convention to call the smaller one (when interpreted as an integer) as the \textbf{positive} square root and the larger one as the \textbf{negative}. This makes sense, as the larger one can always be computed as the modulus minus the smaller one, which is the definition of the negative in prime fields. 


\begin{example} [Quadratic (Non)-Residues and roots in $ \F_5 $] Let us consider our example prime field $\F_5$ again. All square numbers can be found on the main diagonal of the multiplication table XXX. As you can see, in $ \Z_5 $ only the numbers $ 0 $, $ 1 $ and $ 4 $ have square roots and we get $ \sqrt{0} = \{0 \} $, $ \sqrt{1} = \{1,4 \} $, $ \sqrt{2} = \emptyset $, $ \sqrt{3} = \emptyset $ and $ \sqrt{4} = \{2,3 \} $. The numbers $0$, $1$ and $4$ are therefore quadratic residues, while the numbers $2$ and $3$ are quadratic non-residues.
\end{example}
In order to describe whether an element of a prime field is a square number  or not, the so called Legendre Symbol can sometimes be found in the literature, why we will recapitulate it here:

Let $ p \in \Prim $ be a prime number and $ y \in \F_p $ an element from the associated prime field. Then the so-called \textit{Legendre symbol} of $ y $ is defined as follows:
\begin{equation}
\label{eq: Legendre-symbol}
\left (\frac{y}{p} \right): =
\begin{cases}
1 & \text{if $ y $ has square roots} \\
-1 & \text{if $ y $ has no square roots} \\
0 & \text{if $ y = 0 $}
\end{cases}
\end{equation}
\begin{example}
Look at the quadratic residues and non residues in $\F_5$ from example XXX again, we can deduce the following Legendre symbols, from example XXX.
$$
\begin{array}{ccccc}
\left (\frac{0}{5} \right) = 0, &
\left (\frac{1}{5} \right) = 1, &
\left (\frac{2}{5} \right) = -1, &
\left (\frac{3}{5} \right) = -1, &
\left (\frac{4}{5} \right) = 1 \;.
\end{array}
$$
\end{example}
The legendre symbol gives a criterion to decide wheather or not an element from a prime field has a quadratic root or not. This however is not just of theoretic use, as the following so called \textit{Euler criterion} gives a compact way to actually compute the Legendre symbol. To see that, let $ p \in \Prim_{\geq 3} $ be an odd 
Prime number and $ y \in \F_p $. Then the Legendre symbol can be computed as 
\begin{equation}
\label{eq: Euler_criterium}
\left (\frac{y}{p} \right) = y^{\frac{p-1}{2}} \;.
\end{equation}
\begin{example}
Look at the quadratic residues and non residues in $\F_5$ from example XXX again, we can compute the following Legendre symbols using the Euler criterium:
\begin{align*}
\left (\frac{0}{5} \right) &= 0^{\frac{5-1}{2}}= 0^2=0\\
\left (\frac{1}{5} \right) &= 1^{\frac{5-1}{2}}= 1^2=1\\
\left (\frac{2}{5} \right) &= 2^{\frac{5-1}{2}}= 2^2=4 = -1\\
\left (\frac{3}{5} \right) &= 3^{\frac{5-1}{2}}= 3^2=4 =-1\\
\left (\frac{4}{5} \right) &= 4^{\frac{5-1}{2}}= 4^2=1
\end{align*}

\end{example}

% I think this isn't needed. Will just leave it here in case this changes
%
%So the question remains how to actually compute square roots in prime field. The following algorithms give a solution
%\begin{definition}[Tonelli-Shanks algorithm]
%\label{def: Tonelli-Shanks}
%Let $ p $ be an odd prime number $ p \in \Prim _{\geq 3} $ and $ y $ a quadratic residue in $ \Z_p $. Then the so-called Tonneli \cite{TA} and Shanks \cite{SD} algorithm computes the two square roots of $ y $. It is defined as follows:
%\begin{enumerate}
%\item Find $ Q, S \in \Z $ with $ p-1 = Q \cdot 2 ^ S $ such that $ Q $ is odd.
%\item Find an arbitrary quadratic non-remainder $ z \in \Z_p $.
%\item
%\begin{algorithmic}
%\State $ \begin{array}{ccccc}
%M: = S, & c: = z ^ Q, & t: = y ^ Q, & R: = y ^{\frac{Q + 1}{2}}, & M, c, t, R \in \Z_p
%\end{array} $
%\While{$ t \neq 1 $}
%\State Find the smallest $ i $ with $ 0 <i <M $ and $ t ^{2 ^ i} = 1 $
%\State $ b: = c ^{2 ^{M-i-1}} $
%\State $ \begin{array}{ccccc}
%M: = i, & c: = b ^ 2, & t: = tb ^ 2, & R: = R \cdot b
%\end{array} $
%\EndWhile
%\end{algorithmic}
%The results are then the square roots $ r_1: = R $ and $ r_2: = p-R $ of $y$ in $\F_p$.
%\end{enumerate}
%\end{definition}

%\begin{remark}The algorithm (\ref{def: Tonelli-Shanks}) works in prime fields for any odd prime numbers. From a practical point of view, however, it is efficient only if the prime number is congruent to $ 1 $ modulo $ 4 $, since in the other case the formula from the proposition \ref{theorem: square_roots}, which can be calculated more quickly, can be used.\end{remark}

\paragraph{Exponentiation} TO APPEAR...
\paragraph{Extension Fields}
% references https://blog.plover.com/math/se/finite-fields.html
We have define prime fields in the previous section. They are basic building locks for cryptography in general ans snarks in particular. However so called \textit{pairing based} snark systems are crcially dependend on group pairings XXX defined over elliptic curves. For those pairings to be non-trivial the elliptic curve must not only be defined over a prime field but over a so called \textit{field extension} of a given prime field.

We therefore have to understand field extensions. To understand them let $p\in \Prim$ be a prime number and $m\in\N$ a natural number. Then there is a field $\F_{p^m}$ with characteristic $p$ and $p^m$ elements. Such a field is called an \textbf{extension field} of the prime field $\F_p$, because it contains $\F_p$ as a subfield. 

Similar to how prime fields $\F_p$ are generated by starting with the ring of integers and then divide by a prime number $p$ and keep the remainder, prime field extensions $\F_{p^m}$ are generated by starting with the ring $\F_p[x]$ of polynomials and then divide them by an irreducible polynomial of degree $m$ and keep the remainder. 

To be more precise let $P\in F_p[x]$ be an irreducible polynomial of degree $m$ with coefficient from our prime field $\F_p$. Then the set of the extension field is given by  the set of all polynomials with a degree less then $m$:
\begin{equation}
\F_{p^m}:=\{a_{m-1} x^{m-1}+a_{k-2}x^{k-2}+\ldots+a_1 x+a_0\;|\; a_i\in \F_p\}
\end{equation}
which can be shown to be the set of all remainders when dividing any polynomial $Q\in \F_p[x]$ by $P$. So elements of the extension field are polynomials of degree less then $m$. This is analog to how $\F_p$ is the set of all remainders, when dividing integers by $p$.   

Addition in then inheritec from $\F_p[x]$, which means that addition on $\F_{p^m}$ is defined as normal addition of polynomials. To be more precise, we have
\begin{equation}
+:\; \F_{p^m}\times \F_{p^m} \to \F_{p^m}\; ,\; (\sum_{j=0}^m a_j x^j,\sum_{j=0}^m b_j x^j)\mapsto \sum_{j=0}^m (a_j+b_j) x^j 
\end{equation}
and we can see that the neutral element is (the polynomial) $0$ and that the additive inverse is given by the polynomial with all negative coefficients.

Multiplication in inheritec from $\F_p[x]$, too, but we have to divide the result by our modulus polynomial $P$, whenever the degree of the resulting polynomial is equal or greater to $m$. To be more precise, we have
\begin{equation}
+:\; \F_{p^m}\times \F_{p^m} \to \F_{p^m}\; ,\; (\sum_{j=0}^m a_j x^j,\sum_{j=0}^m b_j x^j)\mapsto \Zdiv{\sum _{n = 0} ^{2m} \sum _{i = 0} ^{n}{a} _{i }{{b} _{n-i}}{x} ^{n}}{P} 
\end{equation}
and we can see that the neutral element is (the polynomial) $1$. It is however not obvious from this definition how the multiplicative looks.

We can easily see from the definition of $\F_{p^m}$ that the field is of characteristic $p$, since the multiplicative neutral element $1$ is equivalent to the multiplicative element $1$ from the underlying prime field and hence $\sum_{j=0}^p 1=0$. Moreover $\F_{p^m}$ is finite and contains $p^m$ many elements, since elements are polynomials of degree $<m$ and every coefficient $a_j$ can have $p$ different values.

One key point is that the construction of $\F_{p^m}$ depends on the choice of an irreducible polynomial and in fact different choices will give different multiplication tables, since the remainders from dividing a product by $P$ will be different..

It can however be shown, that the fields for different choices of $P$ are isomorphic, which means that there is a one to one identification between all of them and hence from an abstract point of view they are the same thing. From an implementations point of view however some choices are better, because they allow for faster computations.

\begin{example}[The Extension field $\F_{3^2}$]In (XXX) we have constructed the prime field $\F_3$. In this example we apply the definition (XXX) of a field extension to construct $\F_{3^2}$. We start by choosing an irreducibe polynomial of degree $2$ with coefficients in $\F_3$. We try 
$P(t)=t^2+1$. Maybe the fastest way to show that $P$ is indeed irreducible is to just insert all elements from $\F_3$ to see if the result is never zero. WE compute
\begin{align*}
P(0) = 0^2+1 &= 1\\
P(1) = 1^2+1 &= 2\\
P(2) = 2^2+1 &=  1+1  = 2
\end{align*}
This implies, that $P$ is irreducible. The set $\F_{3^2}$ then contains all poynomials of degrees lower then two with coefficients in $\F_3$, which is precisely
$$
\F_{3^2}=\{0,1,2,t,t+1,t+2,2t,2t+1,2t+2\}
$$
So our extension field contains $9$ elements as expected. Addition is  defined as addition of polynomials. For example $(t+2) + (2t+2)= (1+2)t +(2+2)= 1$. Doing this computation for all elements give the following addition table
\begin{center}
  \begin{tabular}{c | c c c c c c c c c}
    + & 0    & 1    & 2    & t    & t+1  & t+2  & 2t   & 2t+1 & 2t+2 \\\hline
    0 & 0    & 1    & 2    & t    & t+1  & t+2  & 2t   & 2t+1 & 2t+2 \\
    1 & 1    & 2    & 0    & t+1  & t+2  & t    & 2t+1 & 2t+2 & 2t   \\
    2 & 2    & 0    & 1    & r+2  & t    & t+1  & 2t+2 & 2t   & 2t+1 \\
    t & t    & t+1  & t+2  & 2t   & 2t+1 & 2t+2 & 0    & 1    & 2    \\
  t+1 & t+1  & t+2  & t    & 2t+1 & 2t+2 & 2t   & 1    & 2    & 0    \\
  t+2 & t+2  & t    & t+1  & 2t+2 & 2t   & 2t+1 & 2    & 0    & 1    \\
   2t & 2t   & 2t+1 & 2t+2 & 0    & 1    & 2    & t    & t+1  & t+2  \\
 2t+1 & 2t+1 & 2t+2 & 2t   & 1    & 2    & 0    & t+1  & t+2  & t    \\
 2t+2 & 2t+2 & 2t   & 2t+1 & 2    & 0    & 1    & t+2  & t    & t+1
  \end{tabular}
\end{center}
As we can see, the group $(\F_3,+)$ is a subgroup of the group $(\F_{3^2},+)$, obtained by only considering the first three rows and columns of this table.

As it was the case in previozs examples, we can use the table to deduce the negative of any element from $\F_{3^2}$. For example in $\F_{3^2}$ we have $-(2t+1)= t+2$, since $(2t+1) + (t+2)=0$ and the negative of an element is that other element, such that the sum gives the additive neutral element.

Multiplication needs a bit more computation, as we first have to multiply the polynomials and then divide the result by $P$ and keep the remainder. To see how this works compute the product of $t+2$ and $2t+2$ in $\F_{3^2}$
\begin{align*}
(t+2) \cdot (2t+2) &= \Zmod{2t^2 + 2t + t + 1}{t^2+1} \\
                   &= \Zmod{2t^2+1}{t^2+1} & \#\; 2t^2+1:t^2+1= 2 + \frac{2}{t^2+1} \\
                   &= 2 
\end{align*}
So the product of $t+2$ and $2t+2$ in $\F_{3^2}$ is $2$. Doing this computation for all elements give the following multiplication table:
\begin{center}
  \begin{tabular}{c | c c c c c c c c c}
$\cdot$ & 0    & 1    & 2    & t    & t+1  & t+2  & 2t   & 2t+1 & 2t+2 \\\hline
      0 & 0    & 0    & 0    & 0    & 0    & 0    & 0    & 0    & 0 \\
      1 & 0    & 1    & 2    & t    & t+1  & t+2  & 2t   & 2t+1 & 2t+2\\
      2 & 0    & 2    & 1    & 2t   & 2t+2 & 2t+1 & t    & t+2  & t+1 \\
      t & 0    & t    & 2t   & 2    & t+2  & 2t+2 & 1    & t+1  & 2t+1  \\
    t+1 & 0    & t+1  & 2t+2 & t+2  & 2t   & 1    & 2t+1 & 2    & t   \\
    t+2 & 0    & t+2  & 2t+1 & 2t+2 & 1    & t    & t+1  & 2t   & 2    \\
     2t & 0    & 2t   & t    & 1    & 2t+1 & t+1  & 2  & 2t+2 & t+2\\
   2t+1 & 0    & 2t+1 & t+2  & t+1  & 2    & 2t   & 2t+2 & t    & 1    \\
   2t+2 & 0    & 2t+2 & t+1  & 2t+1 & t    & 2    & t+2  & 1     & 2t
  \end{tabular}
\end{center}
As it was the case in previous examples, we can use the table to deduce the multiplicative inverse of any non-zero element from $\F_{3^2}$. For example in $\F_{3^2}$ we have $(2t+1)^{-1}= 2t+2 $, since $(2t+1) \cdot (2t+2)=1$.

From the multiplication table we can also see, that the only quadratic residues in $\F_{3^2}$ are the set $\{0,1,2, t, 2t\}$, with
$\sqrt{0}=\{0\}$, $\sqrt{1}=\{1,2\}$, $\sqrt{2}=\{t, 2t\}$, $\sqrt{t}=\{t+2,2t+1\}$ and $\sqrt{2t}=\{t+1,2t+2\}$.    

Computations in extension fields are arguably on the edge of what can reasonbly be done with pen and paper. Fortunately sage provides us with a simple way to do the computations.
\begin{sagecommandline}
sage: Z3 = GF(3) # prime field
sage: Z3t.<t> = Z3[] # polynomials over Z3
sage: P = Z3t(t^2+1)
sage: P.is_irreducible()
sage: F3_2.<t> = GF(3^2, name='t', modulus=P)
sage: F3_2
sage: F3_2(t+2)*F3_2(2*t+2) == F3_2(2)
sage: F3_2(2*t+2)^(-1) # multiplicative inverse
\end{sagecommandline}
\end{example}


%\paragraph{Hash to Prime fields} 
% https://crypto.stackexchange.com/questions/78017/simple-hash-into-a-prime-field
%An important problem in elliptic curve cryptography and in its implementations as a snark is the ability to hash to (various subsets) of elliptic curves. As we will see in XXX those curves are usually defined over prime fields and hashing to a curve often starts with hashing to the prime field. In this paragraph we therefore look at common techniques to hash to a prime field.

%In what follows let $\F_{q}$ be a prime field, such that $q$ is a prime number with $m$-digits in its binary representation, i.e. $|p_{base_2}|=m$ and let $H:\{0,1\}^* \to \{0,1\}^k$ be a hash function. The methods to map $H$ onto $\F_{q}$ depend on $k$. 

%If $k\leq m-1$, then every image $H(data)$ if interpreted as an integer in its base-2 representation, is smaller then $p$ and hence can directly be interpreted as an element of $\F_{q}$. So in this case $H:\{0,1\}^* \to \F_q$ can be used unchanged. The drawback of this simple method, is that the bigger the difference between $k$ and $m$ is, the more will the distribution of $H$ deviate from uniformity.

%For example in the extreme case $k=1$, $H$ only maps to $\{0,1\}\subset \F_q$. The best possible case is therefore $k=m-1$. In that case only the highest XXX numbers (DO THE COMPUTATION) are missing from the distribution.

%On the other hand if $k\geq m$, then there are basically two commonly used methods to map the output of $H$ onto $\F_q$. The first is to simply forget all leading $k-m+1$-bits from the image of $H$, which brings you back to our previous consideration.

%The second method is to interpret $H(data)$ as an integer and then compute the modulus $ \Zmod{H(data)}{p}$. This also introduces a small bias (COMPUTATION FROM THE FORUM ENTRY). 

%\begin{example}[p\&{}p-$\F_{13}$-mod-hash]
%Consider our pen\&paper hash function from XXX. We want to use this hash function, to define a $16$-bounded hash function that maps into the prime field $\F_{13}$. We define:
%$$\mathcal{H}_{mod}^{13}: \{0,1\}^{16}\to \F_{13}: S \mapsto \Zmod{\mathcal{H}_{PaP}(S)}{13}$$
%Considering the string $S=(1110011101110011)$ from example XXX again we know $\mathcal{H}_{PaP}(S)=(1110)$ and since $(1110)_{10}=14$ and $\Zmod{14}{13}=1$ we get $\mathcal{H}_{mod}^{13}(S)=1$.
%\end{example}

%\begin{example}[p\&{}p-$\F_{13}$-drop-hash]We can consider the same pen\&paper hash function from XXX and define another hash into $\F_{13}$, by deleting the first leading bit from the hash. The result is then a $3$-digit number and therefore guaranteed to be smaller then $13$, since $13$ is equal to $(1101)$ in base $2$.  

%Considering the string $S=(1110011101110011)$ from example XXX again we know $\mathcal{H}_{PaP}(S)=(1110)$ and stripping of the leading bit we get $(110)_{10}=6$ as our hash value.  

%As we can see this hash function has the drawback of an uneven distribution in $\F_{13}$. In fact this hash function is unable to map to values from $\{8,9,10,11,12\}$ as those numbers have a $1$-bit in position $4$. However as we will see in XXX, this hash is cheaper to implement as a circuit as no expensive modulus operation has to be used.
%\end{example}
