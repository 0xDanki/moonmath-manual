\chapter{Circuit Compiler} 
% finite field arithmetics https://johnkerl.org/doc/ffcomp.pdf
As we have seen in the previous chapter, statements can be formalized as membership or knowledge claims in formal language and both algebraic circuits as well as rank-1 constraints systems are two practically important ways to define those languages.

However both algebraic circuits and rank-1 constraints systems are not ideal from a developers point of view, because they deviate substancially from common programing paradigms. Writing real world applications as circuits and the associated verification in terms of rank-1 constraint systems is as least as troublesome as writing any other low level language like assembler code. To allow for complex statement design it is therefore necessary to have some kind of compiler framework, capable to transform high level languages into arithmetic circuits and associated rank-1 constraint systems. 

As we have seen in XXX as well as XXX and XXX, both arithmetic circuits and rank-1 constraint systems have a modularity property by which it is possible to synthezise complex circuits from simpler ones. A basic approach taken by many circuit/R1CS compilers like (LIST) is therefore to provide a library of atomic and simple circuits and then define a way to combine those basic building blocks into arbitrary complex systems.

In this chapter we will provide an introduction to basic concepts of so called \textit{circuit compilers} and derive a toy language which we can "compile" in a pen and paper approach into algebraic circuits and their associated rank-1 constraints systems.

We start with a general introduction to our language and then intoduce atomic types like booleans, unsigned integers and define the fundamental control flow primitives like the if-then-else conditional and the bounded loop. We will look at basic functionality primitives like elliptic curve cryptography and cryptographic hash functions. Primitives like those are often called \textbf{gadgets} in the literature. 
\section{The PAPER Language} To explain basic concepts of circuit compiler and their associated high level languages, we derive an informal toy language and associated brain compiler named \texttt{PAPER} (\textbf{P}en \textbf{A}nd \textbf{P}aper \textbf{E}xecution \textbf{R}ules). \texttt{PAPER} allows programmers to define statements in Rust-like pseudo-code. 

In a \textit{setup phase} the code can then be compiled in a pen and paper approach into visual circuits. The language is inspired by \texttt{ZOKRATES} and \texttt{circom}. Once a circuit is derived it can be executed in a \textit{proofer phase} to generate a valid assignment, which is interpreted as a constructive statement proof. As we will see in the next chapter, such a constructive proof can then be used to compute a succinct zero-knowledge proof for the same statement. 

\paragraph{The Grammar}
In \texttt{PAPER} any statement is defined as an ordered list of functions, where any function has to be declared in the list before it is called in another function of that list. The last entry in a statement has to be a special function, called \texttt{main}. Functions take a list of typed parameters as inputs and compute a list of typed parameters as output. Any statement is parameterized over the field that the circuit will be defined on and has additional optional parameters of unsigned type, needed to define the size of array or the counter of bounded loops. The following definition makes the grammar of a statement precise using a command line language like description: 
% used the command line style formalized e.g. here: http://docopt.org/
\begin{lstlisting}
statement <Name> {F:<Field> [ , <N_1: unsigned>,... ] } {
  [fn <Name>([[pub]<Arg>:<Type>,...])->([[pub]<Rslt>:<Type>,...]){
    [ constant <Const>:<Type>=<Value> ;... ]
    Rslt<==(fn([<Arg>|<Const>,...])|(<Arg>|<Const>)) ;
  } ;...]
  fn main([[pub]<Arg>:<Type>,...])->([[pub]<Rslt>:<Type>,...]){
    [ constant <Const>:<Type>=<Value> ;... ]
    Rslt<==(fn([<Arg>|<Const>,...])|(<Arg>|<Const>)) ;
  } ;
}
\end{lstlisting}
Function arguments are private by default but can be declared as public by the \texttt{pub} specifier. Declaring variables as public always overwrites any previous or conflicting private declaration. 
\begin{example}The following is an example of high level code that follows the grammar of the \texttt{PAPER} language. 
\begin{lstlisting}
statement MOCK_CODE {F: F_43, N_1 = 1024, N_2 = 8} {
  fn foo(in_1 : F, pub in_2 : TYPE_2)->(pub out_1 : F){
    constant c_1 : F = 0 ;
    constant c_2 : TYPE_2 = SOME_VALUE ;
    out_1<== c_1 ;
  } ;
  
  fn bar(pub in_1 : F)->(out_1 : F){
    out_1<==foo(in_1);
  } ;
    
  fn main(in_1 : TYPE_1)->(out_1 : F, out_2 : TYPE_2){
    constant c_1 : TYPE_1  = SOME_VALUE ;
    constant c_2 : F = 2;
    constant c_3 : TYPE_2  = SOME_VALUE  ;
    c_1 <== in_1 ;
    out_1 <== foo(c_2) ;
    out_2 <== TYPE_2 ;
  } ;
}
\end{lstlisting}
\end{example}
\paragraph{The Setup Phase}
In \texttt{PAPER} any function is a high level description of a circuit. The compiler draws a box-node for every argument of a function 

of the circuit labeled with the arguments name that represent variables and there are no other source nodes labeled with variables in the functions circuit. 

If the function has return values, they are compiled to sink nodes of the circuit labeled with the result name that represent variables and there are no other sink nodes labeled with variables in the functions circuit. 

The compiler draws a box-node for every constant that is declared in the function and labels it with the value of that constant.

THEN ASSOCIATES CONSTRAINT CIRCUITS TO THE TYPES. THEN VALIDITY AND TYPE CHECK

DRAW SUBGRAPH FOR ARGUMENTS AND RESULTS. IF BASEFIELD DRAW BOX ELSE DRAW TYPE.

The compiler checks, if every result value is the left side of an \texttt{<==} operator. If the associated right side is not a function an edge is drawn from the right side to the left side. LABEL!!! 

If the right side is a function, the compiler substitutes the box-node that represents that function. If that function is in the \texttt{PAPER} library, the box node will be replaced by the circuit from the library. 

The compiler draws a box-node for every occurence of the \texttt{<==} operator and lables it with the right side of that operator. It then draws an edge to the node on the left side of the operator. If the left side represents a private result it gets label $W$ and if public it gets label $I$ indexed by a unique symbol.

If the right side of the \texttt{<==} operator is another function, the compiler substitutes the box-node that represents that function. If that function is in the \texttt{PAPER} library, the box node will be replaced by the circuit from the library. 

OPTIMIZATION: COLLAPSING BOX NODES IN PATHS.

\texttt{PAPER} is then build on simple substitution rules and a circuit library that provides basic circuit building blocks.  





In contrast to normal executable programs, programs for circuit compilers have two modes of execution. The first mode is usally called \textit{setup phase} is executed in order to generate the circuit and its associated rank-1 constraint system, the letter of which is then usually used as input to some zero knowledge proofing system.

The second mode of execution is usually called the \textit{proofer phase} and in this phase a proofer usually computes a valid assignment to the circuit. Depending on the usecase this valid assignment is then either directly used as constructive proof for proper circuit execution or is transfered as input to the proof generation algorithm of some zero knowledge proofing system, where the full size, non hiding constructive proof is processed into a succinct proof with various levels of zero-knowledge.

Modern circuit languages and their associated compilers abstract over those two phase and provide a unified interphase to the developer, who then writes a single program that can be used in both phases. 


\paragraph{Setup Phase}
\begin{itemize}
\item Compilation starts with an empty circuit and on function \texttt{main}.
\begin{itemize}
\item  draw an input node and label the node with the name of the input.
\item If the input is a variable draw the edge label $S_j$ on ever outgoing edge
\item draw the constraining circuit of the type
\end{itemize}
\item For every output:
\begin{itemize}
\item  draw an output node and label the node with the name of the out.
\item If the output is a variable draw the edge label $S_j$ on the ingoing edge
\item If the output is a constant draw the edge label $S_value$ on its ingoing edge
\end{itemize}
\item check if all modules are defined
\item type check the module body 
\item Draw edges from the input nodes to the output nodes by inductively rewriting all modules in the module body with their associated circuits and replace all edges label with witness labels.
\end{itemize}
\begin{example}[A trivial Circuit] To give an intuition of how to write and compile circuits in the \texttt{PAPER} language, consider the following statement description:
\begin{lstlisting}
statement trivial_circuit {F:F_13} {
  def main{F}(in1 : F, pub in2 : F) -> (out1:F, out2:F){

    let const outc1 : F = 0 ;   
    let const inc1 : F = 7 ;

    out1 <== inc1;
    out2 <== in1;
    outc1 <== in2;
  }
}
\end{lstlisting} 
To compile this statement into an algebraic circuit we use \texttt{PAPER}. According to those rule we start with an empty circuit evaluate function \texttt{main}, which is the only function in this statement. 

We then draw box-nodes for every argument and every return value of the function as well as for every constant that was declared in the function. Then we have to draw a constraint circuit for every type. As we will see in paragraph XXX, the field type has no associated constraints, so we don't need to draw any circuits associated the types of the variables. 

After that we check that there is one \texttt{<==} operator for every result value of the function. We then check the validity of every expression in the \texttt{circuit} section of the module, including a type check. Since the circuit only wires inputs to outputs and all inputs are of the same type as all outputs, the check is valid.

We evaluate those operators. Since in our case the right side of each edge operator is not a function, we draw edges from the box-nodes on the right side to the associated box node on the left side. We get the following edges
\begin{align*}
E(inc1, out1) \\
E(in1, out2) \\
E(in2, outc1)
\end{align*}
To label those edges, we use the general rules of algebraic circuits as defined in XXX. According to those rules every incoming edge of a sink node has a label and every outgoing edge of a source node has a label, if the node is labeled with a variable.

Since nodes that represent constants are implicitly assumed to be private and since the private public specifiers determine if we have to choose the symbol $W$ or $I$ for the edge labels, we get the following circuit:
\begin{center}
\digraph[scale=0.4]{TRIVIAL1}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 [shape=box, label="in_1"];
	n2 [shape=box, label="in_2"];
	n3 [shape=box, label="7"];
	n4 [shape=box, label="out_1"];
	n5 [shape=box, label="out_2"];
	n6 [shape=box, label="0"];
	
	n1 -> n5 [xlabel="W_(in_1)"] ;
	n2 -> n6 [xlabel="I_(in_2)"] ;
	n3 -> n4 ;
}
\end{center}
\end{example}
\section{Common Programing concepts}
In this section we cover concepts that appear in almost every programming language and we see how they can be implemented in circuit compilers. 
\subsection{Primitive Types} 
% https://zeroknowledge.fm/172-2/ reference for all the languages
Primitive data types like booleans, (unsigned) integers, or strings  are the most basic building blocks one might expect in every general high level programing language. In order to write statements as computer programs that compile into circuits, it is therefore necessary to implement primitive types as constraints systems and define their associated operations as circuits.

In this section we will look at some common ways to achieve this. After a recapitulation of the atomic type of prime field elements, we start with an implementation of the boolean type and its associated boolean algebra as circuits. After that we define unsigned integers on top of the boolean type. and leave the implementation of signed integers as an exercise to the reader. 

It should be noted however that while in common programing languages like C, Go, or Rust primitive data types have a one-to-one correspondence with objects in the computer's memory. This is different for most languages that compile into algebraic circuits. As we will see in the following paragraphs, common primitives like booleans or unsigned integers require many constraints and memory. Primitives different from the underlying field elements can be expensive.

\subsubsection{The Basefield type} 
Since both algebraic circuits and their associated rank-1 constraint systems are defined over a finite field, elements from that field are the atomic informational units in those models. In this sense field elements $x\in \F$ are for algebraic circuits what bits are for computers. 

In \texttt{PAPER} we write \texttt{F} for this type and specify the actual field instance for every statement in curly brackets after the name of that statement. Two functions are associated to this type, which are induced by the \textit{addition} and \textit{multiplication} law in the field \texttt{F}. We write
\begin{equation}
\mathtt{MUL}:\; \mathtt{F} \times \mathtt{F} \to \mathtt{F}\;;\; (x,y) \mapsto \mathtt{MUL}(x,y)
\end{equation}
\begin{equation}
\mathtt{ADD}:\; \mathtt{F} \times \mathtt{F} \to \mathtt{F}\;;\; (x,y) \mapsto \mathtt{ADD}(x,y)
\end{equation}
Circuit compilers have to compile these functions into the algebraic gates, as explained in XXX. Every other function has to be expressed in terms of them and proper wireing.

To represent addition and multiplication in the \texttt{PAPER} language, we defin the following two functions:
\begin{lstlisting}
fn MUL(x : F, y : F) -> (MUL(x,y):F){}
\end{lstlisting}  
\begin{lstlisting}
fn ADD(x : F, y : F) -> (ADD(x,y):F){}
\end{lstlisting}
The compiler then compiles every occurence of the $\mathtt{MUL}$ or the $\mathtt{ADD}$ function into the following circuits:
\begin{center}
\digraph[scale=0.5]{FNMUL}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 [shape=box, label="x"];
	n2 [shape=box, label="y"];
	n3 [label="*"];	
	n4 [shape=box, label="(x*y)"];
	
	n1 -> n3 [xlabel="W_1"] ;
	n2 -> n3 [xlabel="W_2"];
	n3 -> n4 [xlabel="W_3"] ;
	
	n5 [shape=box, label="x"];
	n6 [shape=box, label="y"];
	n7 [label="+"];	
	n8 [shape=box, label="(x+y)"];
	
	n5 -> n7 [xlabel="W_1"] ;
	n6 -> n7 [xlabel="W_2"];
	n7 -> n8 [xlabel="W_3"] ;
}
\end{center}
\begin{example}[Basic gates] To give an intuition of how a real world compiler might transform addition and multiplication in algebraic expressions into a circuit, consider the following \texttt{PAPER} statement:
\begin{lstlisting}
statement basic_ops {F:F_13} {
  fn main(in_1 : F, pub in_2 : F) -> (out_1:F, out_2:F){
    out_1 <== MUL(in_1,in_2) ;
    out_2 <== ADD(in_1,in_2) ;
  }
}
\end{lstlisting} 
To compile it into an algebraic circuit we start with an empty circuit and evaluate function \texttt{main}, which is the only function in this statement. 

We draw an inputs subgraph containing box-nodes for every argument of the function and an outputs subgraph containing boxe-nodes for every factor in thereturn value. Since all of these nodes represent variables of the \texttt{field} type, we don't have to add any type constraints to the circuit.

We check the validity of every expression on the right side of every \texttt{<==} operator including a type check. In our case every variable is of \texttt{field} type and hence the types match the types of the \texttt{MUL} as well as the \texttt{ADD} function and the type of the left sides of \texttt{<==}. 

We evaluate the expressions on the right side of every \texttt{<==} operator inductively, replacing every occurence of a function by a subgraph that represents its associated circuit.

According to \texttt{PAPER} every occurence of the \texttt{public} specifier overwrites the associate \texttt{private} default value. Using the appropriate edge labels we get: 
\begin{center}
\digraph[scale=0.5]{BASICOPS}{
    forcelabels=true;
    //center=true;
    splines=ortho;
    nodesep= 2.0;

    subgraph cluster_input {
        nin1 [shape= box, label="in_1"] ;
        nin2 [shape= box, label="in_2"] ;
        color=lightgray ;
        label="inputs" ;
    }

    subgraph cluster_output {
        nout1 [shape= box, label="out_1"] ;
        nout2 [shape= box, label="out_2"] ;
        color=lightgray ;
        label="outputs" ;
    }

    subgraph cluster_mul {
	    nmul1 [shape=box, label="x"];
	    nmul2 [shape=box, label="y"];
	    nmul3 [label="*"];	
	    nmul4 [shape=box, label="(x*y)"];
	    
	    nmul1 -> nmul3 [xlabel="W_1 "] ;
	    nmul2 -> nmul3 [xlabel="W_2"];
	    nmul3 -> nmul4 [xlabel="W_3 "] ;
        color=lightgray ;
        label="fn MUL" ;
    }
    
    subgraph cluster_add {
	    nadd1 [shape=box, label="x"];
	    nadd2 [shape=box, label="y"];
	    nadd3 [label="+"];	
	    nadd4 [shape=box, label="(x+y)"];
	    
	    nadd1 -> nadd3 [xlabel="W_1"] ;
	    nadd2 -> nadd3 [xlabel="W_2 "];
	    nadd3 -> nadd4 [xlabel="W_3 "] ;
        color=lightgray ;
        label="fn ADD" ;
    }    
    // subgraph connectors
    nin1 -> {nmul1, nadd1} [xlabel="W_1", style=dashed, color=grey] ;  
    nin2 -> {nmul2, nadd2} [xlabel="I_2 ", style=dashed, color=grey] ;
    nmul4 -> nout1 [headlabel="W_3 ", style=dashed, color=grey] ;    
    nadd4 -> nout2 [headlabel="W_4 ", style=dashed, color=grey] ;    
}
\end{center}
Any real world compiler might process its associated high level language in a similar way, replacing functions, or gadgets by predefined associated circuits. This process is then often followed by various optimization steps that try to reduce the number of constraints as much as possible.

In \texttt{PAPER}, we optimize this circuit by collapsing all box nodes that are directly connected to other box nodes, adhering to the rule that a variables \texttt{public} specifier overwrites any \texttt{private} specifier. Reindexing edge labels we get the following circuit as our pen and pencil compiler output: 
\begin{center}
\digraph[scale=0.5]{BASICOPSOPTI}{
    forcelabels=true;
    //center=true;
    splines=ortho;
    nodesep= 2.0;

    n1 [shape= box, label="in_1"] ;
    n2 [shape= box, label="in_2"] ;
    n3 [shape= box, label="out_1"] ;
    n4 [shape= box, label="out_2"] ;
	n5 [label="*"] ;	
	n6 [label="+"] ;    
	
    n1 -> {n5, n6} [xlabel="W_1"] ;  
    n2 -> {n5, n6} [xlabel="I_2 "] ;
    n5 -> n3 [xlabel="W_3 "] ;    
    n6 -> n4 [label=" W_4"] ;    
}
\end{center}
\end{example} 
\begin{example}[$3$-factorization] Consider our $3$-factorization problem from example XXX and the associated circuit $C_{3.fac\_zk}(\F_{13})$ we provided in example XXX. To understand the process of replacing high level functions by their associated circuits, inductively, we want define a \texttt{PAPER} statement, that we brain compile into an algebraic circuit equivalent to $C_{3.fac\_zk}(\F_{13})$. We write
\begin{lstlisting}
statement 3_fac_zk {F:F_13} {
  fn main(x_1 : F, x_2 : F, x_3 : F) -> (pub 3_fac_zk : F){
    f_3.fac_zk <== MUL( MUL( x_1 , x_2 ) , x_3 ) ;
  }
}
\end{lstlisting} 
Using \texttt{PAPER}, we start with an empty circuit and then add $3$ input nodes to the input subgraph as well as $1$ output node to the output subgraph. All these nodes are decorated with the associated variable names. Since all of these nodes represent variables of the \texttt{field} type, we don't have to add any type constraints to the circuit.

We check the validity of every expression on the right side of the single \texttt{<==} operator including a type check. 

We evaluate the expressions on the right side of every \texttt{<==} operator inductively. We have two nested multiplication functions and we replace them by the associated multiplication circuits, starting with the most outer function. We get: 
\begin{center}
\digraph[scale=0.5]{PAPER3FUC}{
    forcelabels=true;
    //center=true;
    splines=ortho;
    nodesep= 2.0;

    subgraph cluster_input {
        nin1 [shape= box, label="x_1"] ;
        nin2 [shape= box, label="x_2"] ;
        nin3 [shape= box, label="x_3"] ;
        color=lightgray ;
        label="inputs" ;
    }

    subgraph cluster_output {
        nout1 [shape= box, label="f_3.fac_zk"] ;
        color=lightgray ;
        label="outputs" ;
    }

    subgraph cluster_mul1 {
	    nmul11 [shape=box, label="x"];
	    nmul12 [shape=box, label="y"];
	    nmul13 [label="*"];	
	    nmul14 [shape=box, label="(x*y)"];
	    
	    nmul11 -> nmul13 [xlabel="W_1"] ;
	    nmul12 -> nmul13 [xlabel="W_2"];
	    nmul13 -> nmul14 [xlabel="W_3"] ;
        color=lightgray ;
        label="fn MUL" ;
    }
    
    subgraph cluster_mul2 {
	    nmul21 [shape=box, label="x"];
	    nmul22 [shape=box, label="y"];
	    nmul23 [label="*"];	
	    nmul24 [shape=box, label="(x*y)"];
	    
	    nmul21 -> nmul23 [xlabel="W_1"] ;
	    nmul22 -> nmul23 [xlabel="W_2"];
	    nmul23 -> nmul24 [xlabel="W_3"] ;
        color=lightgray ;
        label="fn MUL" ;
    }    
    // subgraph connectors
    nin1 -> nmul11 [xlabel="W_1", style=dashed, color=grey] ;  
    nin2 -> nmul12 [xlabel="W_2", style=dashed, color=grey] ;
    nin3 -> nmul22 [xlabel="W_3", style=dashed, color=grey] ;    
    nmul14 -> nmul21 [xlabel="W_4", style=dashed, color=grey] ;   
    nmul24 -> nout1 [xlabel="I_1", style=dashed, color=grey] ;   
}
\end{center} 
In a final optimization step we collaps all box nodes directly connected to other box nodes, adhering to the rule that a variables \texttt{public} specifier overwrites any \texttt{private} specifier. Reindexing edge labels we get the following circuit:
\begin{center}
\digraph[scale=0.5]{PAPER3FUCOPTI}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 [shape=box, label="x_1"];
	n2 [shape=box, label="x_2"];
	n3 [shape=box, label="x_3"];
	n4 [shape=box, label="f_3.fac_zk"];
	n5 [label="*"];
	n6 [label="*"];	
	
	n1 -> n5 [xlabel="W_1"] ;
	n2 -> n5 [xlabel="W_2"] ;
	n3 -> n6 [xlabel="W_3"];
	n5 -> n6 [xlabel="W_4"] ;
	n6 -> n4 [xlabel="I_1"];
}
\end{center} 
\end{example}
\paragraph{The Subtraction Constraints System} By definition, algebraic circuits only contain addition and multiplication gates and it follows thar there is no single gate for field subtraction, despite the fact that subtraction is a native operation in every field.

High level languages and their associated circuit compilers therefore need another way to deal with subtraction. To see how this can be achieved, recall that subtraction is defined by addition with the additive inverse and that the inverse can be computed efficiently by multiplication with $-1$. A circuit for field subtraction is therefore given by
\begin{center}
\digraph[scale=0.4]{BTSUB}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 -> n5 [xlabel="S_1    "];
	n2 -> n4 [xlabel="S_2    "];
	n3 -> n4 ;
	n4 -> n5 ;
	n5 -> n6 [xlabel="S_3    "];
	n1 [shape=box, label="x"];
	n2 [shape=box, label="y"];
	n3 [shape=box, label="-1"];
	n4 [label="*"];	
	n5 [label="+"];
	n6 [shape=box, label="SUB(x,y)"]
}
\end{center}
Using the general mothod from XXX, the circuits associated rank-1 constraint system is given by:
\begin{equation}
\left(S_1 + (-1)\cdot S_2\right)\cdot 1 = S_3
\end{equation}
Any valid assignment $\{S_1,S_2, S_3\}$ to this circuit therefore enforces the value $S_3$ to be the difference $S_1- S_2$.

Real world compiler usually provide a gadget or a function to abstract over this circuit, such that programers can use subtraction as if it were native to circuits.
In \texttt{PAPER} we define the following subtraction function that compiles to the previous circuit:
\begin{lstlisting}
fn SUB(x : F, y : F) -> (SUB(x,y) : F){
  constant c : F = -1 ;
  SUB <== ADD(x , MUL( y ,  c) );
}
\end{lstlisting}
In the setup phase of a statement we compile every occurence of the $\mathtt{SUB}$ function into an instance of its associated subtraction circuit and edge labels are generated according to the rules from XXX.
\paragraph{The Inversion Constraint System} By definition, algebraic circuits only contain addition and multiplication gates and it follows thar there is no single gate for field inversion, despite the fact that inversion is a native operation in every field. 

If the underlying field is a prime field, one approach would be to use Fermat's little theorem XXX to compute the multiplicative inverse inside the circuit. To see how this works let $\F_p$ be the prime field. The multiplicative inverse $x^{-1}$ of a field element $x\in\F$ with $x\neq 0$ is then given by $x^{-1}= x^{p-2}$ and computing $x^{p-2}$ in the circuit therefore computes the multiplicative inverse. 

Unfortunately, real world primes $p$ are large and computing $x^{p-2}$ by repeaded multiplication of $x$ with itself is infeasible. A double and multiply approach as described in XXX is faster as it computes the power in roughly $log_2(p)$ steps, but still adds a lot of constraints to the circuit. 

Computing inverses in the circuit makes no use of the fact, that inversion is a native operation in any field. A more constraints friendly approach is therefore to compute the multiplicative inverse outside of the circuit and then only enforce correctness of the computation in the circuit. 

To understand how this can be achieved, observe that a field element $y\in \F$ is the mutiplicative inverse of a field element $x\in \F$, if and only if $x\cdot y =1$ in $\F$. We can use this and define a circuit, that has two inputs $x$ and $y$ and enforces $x\cdot y =1$. It is then guranteed that $y$ is the multiplicative inverse of $x$. The price we pay is that we can not compute $y$ by circuit execution, but auxillary data is needed to tell any proofer which value of $y$ is needed for a valid circuit assignment.  The following circuit defines the constraint
\begin{center}
\digraph[scale=0.4]{BTINV}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 -> n3 [xlabel="S_1  "];
	n2 -> n3 [xlabel="S_2  "];
	n3 -> n4 [xlabel="S_3 =1  "];
	n1 [shape=box, label="x"];
	n2 [shape=box, label="x^(-1)"];
	n3 [label="*"];	
	n4 [shape=box, label="1"];	
}
\end{center}
Using the general method from XXX, the circui is transformed into the following rank-1 constraint system:
\begin{equation}
S_1 \cdot S_2 = 1
\end{equation}
Any valid assignment $\{S_1,S_2\}$ to this circuit enforces that $S_2$ is the multiplicative inverse of $S_1$ and since there is no field element $S_2$, such that $0\cdot S_2=1$, it also handles the fact, that the multiplicative inverse of $0$ is not defined in any field. 

Real world compiler usually provide a gadget or a function to abstract over this circuit and those functions compute the inverse $x^{-1}$ as part of their witness generation process. Programers then don't have to care about providin the inverse as auxiliry data to the circuit. In \texttt{PAPER} we define the following inversion function that compiles to the previous circuit:
\begin{lstlisting}
fn INV(x : F, y : F) -> (x_inv : F) {
  constant c : F = 1 ;
  c <== MUL( x ,  y ) ) ;
  x_inv <== y ;
}
\end{lstlisting}
As we see, this functions takes two inputs, the field value and its inverse. It therefore does not handle the computation of the inverse by itself. This is to keep \texttt{PAPER} as simple as possible. 

In the setup phase we compile every occurence of the $\mathtt{INV}$ function into an instance of the inversion circuit XXX and edge labels are generated according to the rules from XXX.
\paragraph{The Division Constraint System} By definition, algebraic circuits only contain addition and multiplication gates and it follows thar there is no single gate for field division, despite the fact that division is a native operation in every field.

Implementing division as a circuit, we use the fact that division is multiplication with the multiplicative inverse. We therefore define divsion as a circuit using the inversion circuit and constraint system from the prvious paragraph. Expensive inversion is computed outside of the circuit and then provided as circuit input. We get 
\begin{center}
\digraph[scale=0.4]{BTDIV}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 -> n6 [xlabel="S_1  "];
	n2 -> n4 [xlabel="S_2  "];
	n3 -> n6 [xlabel="S_3  "];
	n3 -> n4 [xlabel="S_3  "];
	n4 -> n5 [xlabel="1  "];
	n6 -> n7 [xlabel="S_4  "];
	n1 [shape=box, label="x"];
	n2 [shape=box, label="y"];
	n3 [shape=box, label="y^(-1)"];
	n4 [label="*"];	
	n5 [shape=box, label="1"];
	n6 [label="*"];	
	n7 [shape=box, label="DIV(x,y)"];	
}
\end{center} 
Using the mothod from XXX, we transform this circuit into the following rank-1 constraint system:
\begin{align*}
S_2 \cdot S_3 &= 1\\
S_1 \cdot S_3 &= S_4
\end{align*}
Any valid assignment $\{S_1,S_2,S_3,S_4\}$ to this circuit enforces $S_4$ to be the field divsion of $S_1$ by $S_2$. It handles the fact, that division by $0$ is not defined, since there is no valid assignment in case $S_2=0$. 

In \texttt{PAPER} we define the following division function that compiles to the previous circuit:
\begin{lstlisting}
fn DIV(x : F, y : F, y_inv : F) -> (DIV : F) {
  DIV <== MUL( x ,  INV( y, y_inv ) ) );
}
\end{lstlisting}
In the setup phase we compile every occurence of the binary $\mathtt{INV}$ operator into an instance of the inversion circuit.
\begin{exercise} Let $\mathtt{F}$ be the field $\F_5$ of modular $5$ arithmetics from example XXX. Brain compile the following \texttt{PAPER} statement into an algebraic circuit:
\begin{lstlisting}
statement STUPID_CIRC {F: F_5} {
  fn foo(in_1 : F, in_2 : F)->(out_1 : F, out_2 : F,){
    constant c_1 : F = 3 ;
    out_1<== ADD( MUL( c_1 , in_1 ) , in_1 ) ;
    out_2<== INV( c_1 , in_2 ) ;
  } ;
    
  fn main(in_1 : F, in_2 ; F)->(out_1 : F, out_2 : TYPE_2){
	constant (c_1,c_2) : (F,F) = (3,2) ;
    (out_1,out_2) <== foo(in_1, in_2) ;
  } ;
}
\end{lstlisting}
\end{exercise}
\begin{exercise} Consider the tiny-jubjub curve from example XXX and its associated circuit XXX. Write a statement in \texttt{PAPER} that brain compiles the statement into a circuit equivalent to the one derived in XXX, assuming that curve points are instances and every other assignment is a witness. 
\end{exercise}
\begin{exercise} Let $\mathtt{F}=\F_{13}$ be the modular $13$ prime field and $x\in\mathtt{F}$ some field element. Define a statement in \texttt{PAPER}, such that given instance $x$ a field element $y\in\mathtt{F}$ is a witness for the statement, if and only if $y$ is the square root of $x$.  

Brain compile the statement into a circuit and derive its associated rank-1 constraint system. Consider the instance $x=9$ and compute a constructive proof for the statement. 
\begin{comment}
statement KNOWLEDGE_OF_SQUARE_ROOT {F} {
  fn SQUARE(x : F)->(xx : F){
    xx<== MUL( x , x ) ;
  } ;
    
  fn main(pub x : F, y : F )->(){
    constant c_1 : F = 0 ;
    c_1 <==  SUB( x , SQUARE( y , y ) );
  } ;
}
\end{lstlisting}
\end{comment}
\end{exercise}
\begin{comment}
\paragraph{Modularity} Implementing bounded computation in algebraic circuits it is often necessary to deal with complex expressions of the field type. As we have seen in XXX and XXX, both algebraic circuits and R1CS have a modularity property, which enables a compiler to derive algebraic circuit implementations for arbitrary circuits. 
\begin{example}
To given an intuition of how real world circuit compilers make use of the modularity property to synthezise complex circuits from high level programs, we derive a circuit for the following \texttt{PAPER} code:
\begin{lstlisting}
def main<F_13>(private x : F, private y : F, private y^(-1) : F ) -> () {

	circuit:
		outc1 == DIV( ADD( , ) , , );
}
\end{lstlisting}
\end{example}
\begin{example} Consider the prime field $\F_{13}$. In this example, we want to derive an algebraic circuit and associated R1CS that enforces a pair $(x,y)\in \F_{13}^2$ to be the sum of two tiny jubjub curve points $(x_1,y_1)$ and $(x_2,y_2)$. We assume that we already know that $(x_1,x_2)$ as well as $(x_2,y_2)$ are tiny jubjub points, that is we assume that they are the inputs to valid assignments of circuit XXX. 

To synthezise the associated circuit, we start with the twisted Edwards addition law XXX of the tiny jubjub curve:
$$
(x,y) = \left(\frac{x_1y_2+y_1x_2}{1+8x_1y_1x_2y_2}, \frac{y_1y_2-3x_1x_2}{1-8x_1y_1x_2y_2} \right)
$$ 
To transformation this expression into a circuit we rewrite it in terms of the binary operators $ADD$, $SUB$, $MUL$, $DIV$ that represent the four fundamental field operations in $\F_{13}$. We get
\begin{align*}
(x,y) & = (\\
  & \scriptstyle DIV(ADD(MUL(x_1,y_2),MUL(y_1,x_2)),
         ADD(1,MUL(8,MUL(MUL(x_1,y_1),MUL(x_2,y_2))))), \\   
  & \scriptstyle DIV(ADD(MUL(y_1,y_2),MUL(MUL(3,x_1),x_2)),
         ADD(1,MUL(8,MUL(MUL(x_1,y_1),MUL(x_2,y_2)))))\\
  & )
\end{align*}
We then proceed inductively choosing circuits for the outer most operators, which in this case are two division circuits. We don't expand their inputs into circuits yet, but only represent the inputs symbolically. For better readability we use the symbols of the next operator only, because otherwise the circuit becomes unreadable. We get:
\begin{center}
\digraph[scale=0.4]{TEA}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	// x-value
	nx1 -> nx6 [xlabel="Ex_1  "];
	nx2 -> nx4 [xlabel="Ex_2  "];
	nx3 -> nx6 [xlabel="Ex_3  "];
	nx3 -> nx4 [xlabel="Ex_3  "];
	nx4 -> nx5 [xlabel="Ex_4  "];
	nx6 -> nx7 [xlabel="Ex_5  "];
	nx1 [shape=box, label="ADD(.,.)"];
	nx2 [shape=box, label="ADD(.,.)"];
	nx3 [shape=box, label="ADD(.,.)_INV"];
	nx4 [label="*"];	
	nx5 [shape=box, label="1"];
	nx6 [label="*"];	
	nx7 [shape=box, label="DIV(ADD(.,.),ADD(.,.))"];
	// y-value
	ny1 -> ny6 [xlabel="Ey_1  "];
	ny2 -> ny4 [xlabel="Ey_2  "];
	ny3 -> ny6 [xlabel="Ey_3  "];
	ny3 -> ny4 [xlabel="Ey_3  "];
	ny4 -> ny5 [xlabel="Ey_4  "];
	ny6 -> ny7 [xlabel="Ey_5  "];
	ny1 [shape=box, label="ADD(.,.)"];
	ny2 [shape=box, label="ADD(.,.)"];
	ny3 [shape=box, label="ADD(.,.)_INV"];
	ny4 [label="*"];	
	ny5 [shape=box, label="1"];
	ny6 [label="*"];	
	ny7 [shape=box, label="DIV(ADD(.,.),ADD(.,.))"];	
}
\end{center}

\end{example}
\end{comment}

\subsubsection{The Boolean Type} 
% implementations can be found here: https://github.com/filecoin-project/zexe/tree/master/snark-gadgets/src/bits
Booleans are a classical primitive type, implemented by virtually every higher programing language. It is therefore a importance to implement booleans in circuits. One of the most common ways to do this is by interpreting the additive and multiplicative neutral element $\{0,1\}\subset \F$ as the two boolean values, such that $0$ represents $false$ and $1$ represents $true$. Boolean operators like $and$, $or$, or $xor$ are then expressable as algebraic computations inside $\F$. 

Representing booleans this way is convinient because the elements $0$ and $1$ are defined in any field. The representation is therefore independent of the actual field in consideration. 

To fix Boolean algebra notation we write $0$ to represent $false$ and $1$ to represent $true$ and we write $\wedge$ to represent the boolean AND as well as $\vee$ to represent the boolean OR operator. The boolean NOT operator is written as $\lnot$. 
\paragraph{The Boolean Constraint System} To represent booleans by the additive and multiplicative neutral elements of a field, a constraint is required to actually enforces variables of boolean type to be either $1$ or $0$. In fact many of the following circuits that represent boolean functions, are only correct under the assumption that their input variables are constraint to be either $0$ or $1$. Not constraining boolean variables is a common issue in circuit design.

In order to constrain an arbitrary field element $x\in \F$ to be $1$ or $0$, the key observation is that the equation $x \cdot (1-x) =0$ has only two solutions $0$ and $1$ in any field. Implementing this equation as a circuit therefore generates the correct constraint:
\begin{center}
\digraph[scale=0.4]{BOOLCONS}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  nCONS1 -> nCONS4 [xlabel="S_1"] ;
  nCONS1 -> nCONS6 [xlabel="S_1  "] ;
  nCONS2 -> nCONS5 ;
  nCONS3 -> nCONS4 ;
  nCONS4 -> nCONS5 ;
  nCONS5 -> nCONS6 ;
  nCONS6 -> nCONS7 [xlabel="0  "] ;
  nCONS1 [shape=box, label="x"] ;
  nCONS2 [shape=box, label="1"] ;
  nCONS3 [shape=box, label="-1"] ;
  nCONS4 [label="*"] ;
  nCONS5 [label="+"] ;
  nCONS6 [label="*"] ;
  nCONS7 [shape=box, label="0"] ;
}
\end{center}
Using the mothod from XXX, we transform this circuit into the following rank-1 constraint system:
$$
S_1 \cdot (1-S_1) = 0
$$
Any valid assignment $\{S_1\}$ to this circuit enforces $S_1$ to be either $0$ or $1$. 

Some real world circuit compilers like \texttt{ZOKRATES} or \texttt{BELLMAN} are typed, while others like \texttt{circom} are not. However all of them have their way of dealing with the binary constraint. In \texttt{PAPER} we define the following boolean type that compiles to the previous circuit:
\begin{lstlisting}
type BOOL(x : F) -> (b : BOOL) { 
	constant c1 : F = 0 ;
	constant c2 : F = 1 ;
	constant c3 : F = -1 ;
    c1 <== MUL( x ,  ADD( c2 , MUL( x , c3) ) ) );
    b <== x ;
}
\end{lstlisting}
In the setup phase of a statement we compile every occurence of a variable of boolean type into an instance of its associated boolean circuit.
\paragraph{The AND operator constraint system} Given two field elements $b_1$ and $b_2$ from $\F$ that are constrained to represent boolean variables, we want to find a circuit that computes the logical \textit{and} operator $AND(b_1,b_2)$ as well as its associated R1CS, that enforces $b_1$, $b_2$, $AND(b_1,b_2)$ to satisfy the constraint system if and only if $b_1\; \wedge \; b_2 =AND(b_1,b_2)$ holds true. 

The key insight here is that given three boolean constraint variables $b_1$, $b_2$ and $b_3$, the equation $b_1\cdot b_2 = b_3$ is satisfied in $\F$ if and only if the equation $b_1\; \wedge \; b_2 = b_3$ is satisfied in boolean algebra. The logical operator $\wedge$ is therefore implementable in $\F$ by field multiplication of its arguments and the following circuit computes the $\wedge$ operator in $\F$, assuming all inputs are restricted to be $0$ or $1$:
\begin{center}
\digraph[scale=0.4]{BOOLAND}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  nAND1 -> nAND3 [xlabel="S_1  "] ;
  nAND2 -> nAND3 [xlabel="S_2"] ;
  nAND3 -> nAND4 [xlabel="S_3  "] ;

  nAND1 [shape=box, label="b_1"] ;
  nAND2 [shape=box, label="b_2"] ;
  nAND3 [label="*"] ;
  nAND4 [shape=box, label="AND(b_1,b_2)"] ;
}
\end{center}
The associated rank-1 constraint system can be deduced from the general process XXX and consists of the following constraint
\begin{equation}
 S_1 \cdot S_2 = S_3
\end{equation}
Common circuit languages typically provide a gadget or a function to abstract over this circuit, such that programers can use the $\wedge$ operator without caring about the associated circuit. In \texttt{PAPER} we define the following function that compiles to the $\wedge$-operator's circuit:
\begin{lstlisting}
fn AND(b_1 : BOOL, b_2 : BOOL) -> AND(b_1,b_2) : BOOL{
  AND(b_1,b_2) <== MUL( b_1 ,  b_2) ;
}
\end{lstlisting}
In the setup phase of a statement we compile every occurence of the $\mathtt{AND}$ function into an instance of its associated $\wedge$-operator's circuit.
\paragraph{The OR operator constraint system} Given two field elements $b_1$ and $b_2$ from $\F$ that are constrained to represent boolean variables, we want to find a circuit that computes the logical \textit{or} operator $OR(b_1,b_2)$ as well as its associated R1CS, that enforces $b_1$, $b_2$, $OR(b_1,b_2)$ to satisfy the constraint system if and only if $b_1\; \vee \; b_2 = OR(b_1,b_2)$ holds true. 

Assuming that three variables $b_1$, $b_2$ and $b_3$ are boolean constraint, the equation $b_1 + b_2 - b_1\cdot b_2 = b_3$ is satisfied in $\F$ if and only if the equation $b_1 \; \vee \; b_2 = b_3$ is satisfied in boolean algebra. The logical operator $\vee$ is therefore implementable in $\F$ by the following circuit, assuming all inputs are restricted to be $0$ or $1$:
\begin{center}
\digraph[scale=0.4]{BOOLOR}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  
  nOR1 [shape=box, label="b_1"] ;
  nOR2 [shape=box, label="b_2"] ;
  nOR3 [shape=box, label="-1"] ;
  nOR4 [label="*"] ;
  nOR5 [label="*"] ;
  nOR6 [label="+"] ;
  nOR7 [label="+"] ;
  nOR8 [shape="box", label="OR(b_1,b_2)"]
  
  nOR1 -> nOR4 [xlabel="S_1"] ;
  nOR1 -> nOR6 [xlabel="S_1"] ;
  nOR2 -> nOR4 [taillabel="S_2 "] ;
  nOR2 -> nOR6 [taillabel="S_2 "] ;
  nOR4 -> nOR5 [headlabel="  S_3"] ;
  nOR3 -> nOR5 ; 
  nOR5 -> nOR7 ;
  nOR6 -> nOR7 ;
  nOR7 -> nOR8 [xlabel="S_4 "] ;

}
\end{center}
The associated rank-1 constraint system can be deduced from the general process XXX and consists of the following constrainst
\begin{align*}
S_1 \cdot S_2 & = S_3\\
(S_1 + S_2 - S_3)\cdot 1 &= S_4
\end{align*}
Common circuit languages typically provide a gadget or a function to abstract over this circuit, such that programers can use the $\vee$ operator without caring about the associated circuit. In \texttt{PAPER} we define the following function that compiles to the $\vee$-operator's circuit:
\begin{lstlisting}
fn OR(b_1 : BOOL, b_2 : BOOL) -> OR(b_1,b_2) : BOOL{
  constant c1 : F = -1 ;
  OR(b_1,b_2) <== ADD(ADD(b_1,b_2),MUL(c1,MUL(b_1,b_2))) ;
}
\end{lstlisting}
In the setup phase of a statement we compile every occurence of the $\mathtt{OR}$ function into an instance of its associated $\vee$-operator's circuit.
\begin{exercise} Let $\F$ be a finite field and let $b_1$ as well as $b_2$ two boolean constraint variables from $\F$. Show that the equation 
$OR(b_1,b_2) = 1 - (1 - b_1)\cdot (1 - b_2)$ holds true.

Use this equation to derive an algebraic circuit with ingoing variables $b_1$ and $b_2$ and outgoing variable $OR(b_1,b_2)$, such that $b_1$ and $b_2$ are boolean constraint and the circuit has a valid assignment, if and only if $OR(b_1,b_2) = b_1 \vee b_2$.  

Use the technique from XXX to transform this circuit into a rank-1 constraint system and find its full solution set. Define a \texttt{PAPER} function that brain compiles into the circuit. 
\begin{comment}
\begin{center}
\digraph[scale=0.4]{BOOLOR}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  nOR1 -> nOR5 [xlabel="S_1  "] ;
  nOR2 -> nOR7 [xlabel="S_2  "] ;
  nOR3 -> {nOR5, nOR7, nOR10} ;
  nOR4 -> {nOR6, nOR8, nOR11} ;
  nOR5 -> nOR6; 
  nOR6 -> nOR9 ;
  nOR7 -> nOR8 ;
  nOR8 -> nOR9 ;
  nOR9 -> nOR10 [xlabel="S_3  "] ;
  nOR10 -> nOR11 ;
  nOR11 -> nOR12 [xlabel="S_4  "] ;

  nOR1 [shape=box, label="b_1"] ;
  nOR2 [shape=box, label="b_2"] ;
  nOR3 [shape=box, label="-1"] ;
  nOR4 [shape=box, label="1"] ;
  nOR5 [label="*"] ;
  nOR6 [label="+"] ;
  nOR7 [label="*"] ;
  nOR8 [label="+"] ;
  nOR9 [label="*"] ;
  nOR10 [label="*"] ;
  nOR11 [label="+"] ;
  nOR12 [shape=box, label="OR(b_1,b_2)"] ;
}
\end{center}
The associated rank-1 constraint system can be deduced from the general process XXX and consists of the following constrainst
\begin{align*}
 (1- S_1) \cdot (1-S_2) & = S_3\\
  (1-S_3)\cdot 1 &= S_4
\end{align*}
Common circuit languages typically provide a gadget or a function to abstract over this circuit, such that programers can use the $\vee$ operator without caring about the associated circuit. In \texttt{PAPER} we define the following function that compiles to the $\vee$-operator's circuit:
\begin{lstlisting}
fn OR(b_1 : BOOL, b_2 : BOOL) -> OR(b_1,b_2) : BOOL{
  constant c1 = 1 ;
  constant c2 = -1 ;
  OR(b_1,b_2) <== ADD(c1,MUL(MUL(ADD(c1,MUL(b_1,c2)),ADD(c1,MUL(b_1,c2))),c2))  ;
}
\end{lstlisting}
In the setup phase of a statement we compile every occurence of the $\mathtt{OR}$ function into an instance of its associated $\vee$-operator's circuit.
\end{comment} 
\end{exercise}
\paragraph{The NOT operator constraint system} Given a field element $b$ from $\F$ that is constrained to represent a boolean variable, we want to find a circuit that computes the logical \textit{NOT} operator $NOT(b)$ as well as its associated R1CS, that enforces $b$, $NOT(b)$ to satisfy the constraint system if and only if $\lnot b = NOT(b)$ holds true. 

Assuming that two variables $b_1$ and $b_2$ are boolean constraint, the equation $(1-b_1) = b_2$ is satisfied in $\F$ if and only if the equation $\lnot b_1 = b_2$ is satisfied in boolean algebra. The logical operator $\lnot$ is therefore implementable in $\F$ by the following circuit, assuming all inputs are restricted to be $0$ or $1$:
\begin{center}
\digraph[scale=0.4]{BOOLNOT}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  nNOT1 -> nNOT4 [xlabel="S_1  "] ;
  nNOT2 -> nNOT4 ;
  nNOT3 -> nNOT5 ;
  nNOT4 -> nNOT5 ;
  nNOT5 -> nNOT6 [xlabel="S_2  "] ;

  nNOT1 [shape=box, label="b"] ;
  nNOT2 [shape=box, label="-1"] ;
  nNOT3 [shape=box, label="1"] ;
  nNOT4 [label="*"] ;
  nNOT5 [label="+"] ;
  nNOT6 [shape=box, label="NOT(b)"] ;
}
\end{center}
The associated rank-1 constraint system can be deduced from the general process XXX and consists of the following constrainst
\begin{align*}
  (1-S_1)\cdot 1 &= S_2
\end{align*}
Common circuit languages typically provide a gadget or a function to abstract over this circuit, such that programers can use the $\lnot$ operator without caring about the associated circuit. In \texttt{PAPER} we define the following function that compiles to the $\lnot$-operator's circuit:
\begin{lstlisting}
fn NOT(b : BOOL -> NOT(b) : BOOL{
  constant c1 = 1 ;
  constant c2 = -1 ;
  NOT(b_1) <== ADD( c1 , MUL( c2 , b) ) ;
}
\end{lstlisting}
In the setup phase of a statement we compile every occurence of the $\mathtt{NOT}$ function into an instance of its associated $\lnot$-operator's circuit.
\begin{exercise}
Let $\F$ be a finite field. Derive the algebraic circuit and associated rank-1 constraint system for the following operators: NOR, XOR, NAND, EQU.
\end{exercise}
\paragraph{Modularity} As we have seen in XXX and XXX, both algebraic circuits and R1CS have a modularity property and as we have seen in this section, all basic boolean functions are expressable in circuits. Combining those two properties, show that it is possible to express arbitrary boolean functions as algebraic circuits.

This shows that the expressiveness of algebraic circuits and therefore rank-1 constraint systems is as general as the expressiveness of boolen circuits. In important implication is that the languages $L_{R1CS-SAT}$ and $L_{Circuit-SAT}$ as defined in XXX, are as general as the famous language $L_{3-SAT}$, which is known to be $\mathcal{NP}$-complete. 
\begin{example} To give an example of how a compiler might construct complex boolean expressions in algebraic circuits from simple one and how to derive their associated rank-1 constraint systems, lets look at the following \texttt{PAPER} statement:
\begin{lstlisting}
statement BOOLEAN_STAT {F: F_p} {
  fn main(b_1:BOOL,b_2:BOOL,b_3:BOOL,b_4:BOOL )-> pub b_5:BOOL {
    b_5 <== AND( OR( b_1 , b_2) , AND( b_3 , NOT( b_4) ) ) ;
  } ;
}
\end{lstlisting}
The code describes a circuit, that takes four private inputs $b_1$, $b_2$, $b_3$ and $b_4$ of boolean type and computes a public output $b_5$, such that the following boolean expression holds true:
$$
\left( b_1 \vee b_2 \right) \wedge (b_3 \wedge \lnot b_4) = b_5
$$
During a setup-phase, a circuit compilers then transforms this high level language statement into a circuit and associated rank-1 constrains systems and hence defines a  language $L_{BOOLEAN\_STAT}$. 

To see how this might be achieved, we use \texttt{PAPER} as an example to execute the setup-phase and compile \texttt{BOOLEAN\_STAT} into a circuit. Taking the definition of the boolean constraint XXX as well as the definitions of the appropriate boolean operators into account, we get the following circuit:
\begin{center}
\digraph[scale=0.2]{BOOLCOMPLEX}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 1.0;
  rankdir=TB;

  subgraph clusterINPUT {
    nb1 [shape=box, label="b_1"] ;
    nb2 [shape=box, label="b_2"] ;    
    nb3 [shape=box, label="b_3"] ;
    nb4 [shape=box, label="b_4"] ;
    color=lightgray;
    label="inputs" ; 
  }
  
  subgraph clusterOUTPUT {
    nout1 [shape=box, label="AND( OR( b1 , b2 ) , AND( b3 , NOT( b4 ) )"]
    color=lightgray;
    label="outputs" ; 
  }
  
  subgraph clusterCONS  {
    subgraph clusterBCONS1 {
      nCONSB11 -> nCONSB14 [xlabel="S_1"] ;
      nCONSB11 -> nCONSB16 [xlabel="S_1"] ;
      nCONSB12 -> nCONSB15 ;
      nCONSB13 -> nCONSB14 ;
      nCONSB14 -> nCONSB15 ;
      nCONSB15 -> nCONSB16 ;
      nCONSB16 -> nCONSB17 [xlabel="w_5=0  "] ;
      nCONSB11 [shape=box, label="b", color=lightgray ] ;
      nCONSB12 [shape=box, label="1"] ;
      nCONSB13 [shape=box, label="-1"] ;
      nCONSB14 [label="*"] ;
      nCONSB15 [label="+"] ;
      nCONSB16 [label="*"] ;
      nCONSB17 [shape=box, label="0"] ;
      color=lightgray;
      label="b1 : BOOL" ;
    }
    
      subgraph clusterBCONS2 {
      nCONSB21 -> nCONSB24 [xlabel="S_1"] ;
      nCONSB21 -> nCONSB26 [xlabel="S_1"] ;
      nCONSB22 -> nCONSB25 ;
      nCONSB23 -> nCONSB24 ;
      nCONSB24 -> nCONSB25 ;
      nCONSB25 -> nCONSB26 ;
      nCONSB26 -> nCONSB27 [xlabel="W_6=0  "] ;
      nCONSB21 [shape=box, label="b", color=lightgray ] ;
      nCONSB22 [shape=box, label="1"] ;
      nCONSB23 [shape=box, label="-1"] ;
      nCONSB24 [label="*"] ;
      nCONSB25 [label="+"] ;
      nCONSB26 [label="*"] ;
      nCONSB27 [shape=box, label="0"] ;
      color=lightgray;
      label="b2 : BOOL" ;
    }
    
    subgraph clusterBCONS3 {
      nCONSB31 -> nCONSB34 [xlabel="S_1"] ;
      nCONSB31 -> nCONSB36 [xlabel="S_1"] ;
      nCONSB32 -> nCONSB35 ;
      nCONSB33 -> nCONSB34 ;
      nCONSB34 -> nCONSB35 ;
      nCONSB35 -> nCONSB36 ;
      nCONSB36 -> nCONSB37 [xlabel="W_7=0  "] ;
      nCONSB31 [shape=box, label="b", color=lightgray ] ;
      nCONSB32 [shape=box, label="1"] ;
      nCONSB33 [shape=box, label="-1"] ;
      nCONSB34 [label="*"] ;
      nCONSB35 [label="+"] ;
      nCONSB36 [label="*"] ;
      nCONSB37 [shape=box, label="0"] ;
      color=lightgray;
      label="b3 : BOOL" ;
    }
    
    subgraph clusterBCONS4 {
      nCONSB41 -> nCONSB44 [xlabel="S_1"] ;
      nCONSB41 -> nCONSB46 [xlabel="S_1"] ;
      nCONSB42 -> nCONSB45 ;
      nCONSB43 -> nCONSB44 ;
      nCONSB44 -> nCONSB45 ;
      nCONSB45 -> nCONSB46 ;
      nCONSB46 -> nCONSB47 [xlabel="W_8=0  "] ;
      nCONSB41 [shape=box, label="b", color=lightgray ] ;
      nCONSB42 [shape=box, label="1"] ;
      nCONSB43 [shape=box, label="-1"] ;
      nCONSB44 [label="*"] ;
      nCONSB45 [label="+"] ;
      nCONSB46 [label="*"] ;
      nCONSB47 [shape=box, label="0"] ;
      color=lightgray;
      label="b4 : BOOL" ;
    } 
    color = white ; 
  } 

  subgraph clusterCIRC{

    subgraph clusterORb1b2 {
      nOR1 [shape=box, label="b_1", color=lightgray] ;
      nOR2 [shape=box, label="b_2", color=lightgray] ;
      nOR3 [shape=box, label="-1"] ;
      nOR4 [label="*"] ;
      nOR5 [label="*"] ;
      nOR6 [label="+"] ;
      nOR7 [label="+"] ;
      nOR8 [shape="box", label="OR(b_1,b_2)", color=lightgray]
      
      nOR1 -> nOR4 [xlabel="S_1"] ;
      nOR1 -> nOR6 [xlabel="S_1"] ;
      nOR2 -> nOR4 [taillabel="S_2 "] ;
      nOR2 -> nOR6 [taillabel="S_2 "] ;
      nOR4 -> nOR5 [headlabel="  S_3"] ;
      nOR3 -> nOR5 ; 
      nOR5 -> nOR7 ;
      nOR6 -> nOR7 ;
      nOR7 -> nOR8 [xlabel="S_4 "] ;
      color=lightgray;
      label="fn OR" ;
    }

    subgraph clusterANDb3NOTb4 {
      nAND21 -> nAND23 [headlabel="  S_1"] ;
      nAND22 -> nAND23 [xlabel="S_2"] ;
      nAND23 -> nAND24 [xlabel="S_3 "] ;

      nAND21 [shape=box, label="b_1", color=lightgray ] ;
      nAND22 [shape=box, label="b_2", color=lightgray ] ;
      nAND23 [label="*"] ;
      nAND24 [shape=box, label="AND( b_1 , b_2 )", color=lightgray] ;
      color=lightgray;
      label="fn AND"
    }

    subgraph clusterNOTb4 {
      nNOT1 -> nNOT4 [xlabel="S_1 "] ;
      nNOT2 -> nNOT4 ;
      nNOT3 -> nNOT5 ;
      nNOT4 -> nNOT5 ;
      nNOT5 -> nNOT6 [headlabel="S_2 "] ;

      nNOT1 [shape=box, label="b", color=lightgray ] ;
      nNOT2 [shape=box, label="-1"] ;
      nNOT3 [shape=box, label="1"] ;
      nNOT4 [label="*"] ;
      nNOT5 [label="+"] ;
      nNOT6 [shape=box, label="NOT( b )", color=lightgray ] ;
      color=lightgray;
      label="fn NOT"
    }

    subgraph clusterAND1 {
      nAND1_1 -> nAND1_3 [xlabel="S_1"] ;
      nAND1_2 -> nAND1_3 [xlabel="S_2 "] ;
      nAND1_3 -> nAND1_4 [xlabel="S_3 "] ;
      nAND1_1 [shape=box, label="b_1", color=lightgray ] ;
      nAND1_2 [shape=box, label="b_2", color=lightgray] ;
      nAND1_3 [label="*"] ;
      nAND1_4 [shape=box, label="AND( b_1 , b_2 )", color=lightgray] ;
      color=lightgray;
      label="fn AND"
    }
    nNOT6 -> nAND22 [style=dashed, color=grey] ;
    nOR8 -> nAND1_1 [style=dashed, color=grey] ;
    nAND24 -> nAND1_2 [style=dashed, color=grey] ;
    
    color = white ; 
  }
  // outer circuit
    nb1 -> nCONSB11 [xlabel="W_1", style=dashed, color=grey] ;
    nCONSB11 -> nOR1 [style=dashed, color=grey] ;
    nb2 -> nCONSB21 [headlabel="W_2", style=dashed, color=grey] ;
    nCONSB21 -> nOR2 [style=dashed, color=grey] ;
    nb3 -> nCONSB31 [xlabel="W_3 ", style=dashed, color=grey] ;
    nCONSB31 -> nAND21 [style=dashed, color=grey] ;
    nb4 -> nCONSB41 [xlabel="W_4", style=dashed, color=grey] ;
    nCONSB41 -> nNOT1 [style=dashed, color=grey] ;
    nAND1_4 -> nout1 [xlabel="I_1"; style=dashed, color=grey] ;

}
\end{center}
Simple optimization then collapses all box-nodes that are directly linked and all box nodes that represent the same constants. After relabeling the edges the following circuit represents the circuit associated to the \texttt{BOOLEAN\_STAT} statement:
\begin{center}
\digraph[scale=0.5]{BOOLCOMPLEXOPTI}{
  forcelabels=true;
  center=true;
  splines=ortho;

  one -> nCONSb15 ;
  minusone -> nCONSb14 ;
  nCONSb14 -> nCONSb15 ;
  nCONSb15 -> nCONSb16 ;
  nCONSb16 -> zero [xlabel="W_5"] ;
  nCONSb14 [label="*"] ;
  nCONSb15 [label="+"] ;
  nCONSb16 [label="*"] ;

  one -> nCONSb25 ;
  minusone -> nCONSb24 ;
  nCONSb24 -> nCONSb25 ;
  nCONSb25 -> nCONSb26 ;
  nCONSb26 -> zero [headlabel="W_6 "] ;
  nCONSb24 [label="*"] ;
  nCONSb25 [label="+"] ;
  nCONSb26 [label="*"] ;

  one -> nCONSb35 ;
  minusone -> nCONSb34 ;
  nCONSb34 -> nCONSb35 ;
  nCONSb35 -> nCONSb36 ;
  nCONSb36 -> zero [taillabel="W_7"] ;
  nCONSb34 [label="*"] ;
  nCONSb35 [label="+"] ;
  nCONSb36 [label="*"] ;

  one -> nCONSb45 ;
  minusone -> nCONSb44 ;
  nCONSb44 -> nCONSb45 ;
  nCONSb45 -> nCONSb46 ;
  nCONSb46 -> zero [taillabel="W_8 "] ;
  nCONSb44 [label="*"] ;
  nCONSb45 [label="+"] ;
  nCONSb46 [label="*"] ;

  //minusone -> {nOR5, nOR7, nOR10} ;
  //one -> {nOR6, nOR8, nOR11} ;
  //nOR5 -> nOR6; 
  //nOR6 -> nOR9 ;
  //nOR7 -> nOR8 ;
  //nOR8 -> nOR9 ;
  //nOR9 -> nOR10 [headlabel="W_9  "] ;
  //nOR10 -> nOR11 ;
  //nOR5 [label="*"] ;
  //nOR6 [label="+"] ;
  //nOR7 [label="*"] ;
  //nOR8 [label="+"] ;
  //nOR9 [label="*"] ;
  //nOR10 [label="*"] ;
  //nOR11 [label="+"] ;
  
  // new 
  //nOR1 [shape=box, label="b_1"] ;
  //nOR2 [shape=box, label="b_2"] ;
  //nOR3 [shape=box, label="-1"] ;
  minusone -> nOR5 ;
  nOR4 [label="*"] ;
  nOR5 [label="*"] ;
  nOR6 [label="+"] ;
  nOR7 [label="+"] ;
  //nOR8 [shape="box", label="OR(b_1,b_2)"]
  
  //nOR1 -> nOR4 [xlabel="S_1"] ;
  //nOR1 -> nOR6 [xlabel="S_1"] ;
  //nOR2 -> nOR4 [taillabel="S_2 "] ;
  //nOR2 -> nOR6 [taillabel="S_2 "] ;
  nOR4 -> nOR5 [taillabel="W_9"] ;
  //nOR3 -> nOR5 ; 
  nOR5 -> nOR7 ;
  nOR6 -> nOR7 ;
  //nOR7 -> nOR8 [xlabel="S_4 "] ;

  nAND23 [label="*"] ;
  minusone -> nNOT4 ;
  one -> nNOT5 ;
  nNOT4 -> nNOT5 ;
  nNOT4 [label="*"] ;
  nNOT5 [label="+"] ;

  nOR7 -> nAND1_3; // here
  nAND23 -> nAND1_3 [xlabel="W_10"] ;
  nAND1_3 -> nAND1_4 [xlabel="I_1 "] ;
  nAND1_3 [label="*"] ;
  nAND1_4 [shape=box, label="AND( OR( b1 , b2 ) , AND( b3 , NOT( b4 ) )"] ;

  // outer circuit
    nNOT5 -> nAND23 ;
    b1 -> nOR4 [taillabel="  W_1"] ;
    b1 -> nOR6 [xlabel="W_1"] ;
    b1 -> nCONSb14 [headlabel="W_1 "] ;
    b1 -> nCONSb16 [headlabel="W_1     "] ;
    b2 -> nOR4 [taillabel=" W_2"] ;
    b2 -> nOR6  [headlabel=""] ;
    b2 -> nCONSb24 [headlabel=" W_2 "] ;
    b2 -> nCONSb26 [headlabel=" W_2 "] ;
    b3 -> nAND23 [xlabel=" W_3 "] ;
    b3 -> nCONSb34 [taillabel=" W_3"] ;
    b3 -> nCONSb36 [taillabel=""] ;
    b4 -> nNOT4 [headlabel=" W_4"] ;
    b4 -> nCONSb44 [headlabel=" W_4"] ;
    b4 -> nCONSb46 [headlabel="W_4"] ;
    b1 [shape=box, label="b1"] ;
    b2 [shape=box, label="b2"] ;
    b3 [shape=box, label="b3"] ;
    b4 [shape=box, label="b4"] ;
    minusone [shape=box, label="-1"] ;
    one [shape=box, label="1"] ;
    zero [shape=box, label="0"] ;
}
\end{center}
Given some public input $I_1$ from $\F_{13}$ a valid assignments to this circuits consists of private inputs $W_1$, $W_2$, $W_3$, $W_4$ from $\F_{13}$, such that the equation $I_1 = \left( W_1 \vee W_2 \right) \wedge (W_3 \wedge \lnot W_4)$ holds true. In addition a valid assignment also has to contain private inputs $W_5$, $W_6$, $W_7$, $W_8$, $W_9$ and $W_{10}$, which can be derived from circuit execution. The inputs $W_5$, $\ldots$, $W_8$ ensure that the first four private inputs are either $0$ or $1$ but not any other field element and the others enforce the boolean operations in the expression.  

To compute the associated R1CS we can use the general method from XXX and look at every labeled outgoing edge not coming from a source node. Declaring the edges coming from input nodes as well as the edge going to the single output node as public and every other edge as private input. In this case we get:
\begin{align*}
W_5:\;\; & W_1 \cdot (1- W_1) = 0  & \text{boolean constraints}\\
W_6:\;\; & W_2 \cdot (1- W_2) = 0 \\
W_7:\;\; & W_3 \cdot (1- W_3) = 0 \\
W_8:\;\; & W_4 \cdot (1- w_4) = 0 \\
W_9:\;\; & W_1 \cdot W_2 = W_9 & \text{ first OR-operator constraint}\\
W_{10}:\;\; & W_3 \cdot (1-W_4) = W_{10} & \text{AND(.,NOT(.))-operator constraints}\\
I_1:\;\; & (W_1 + W_2 -W_9) \cdot W_{10} = I_1 & \text{AND-operator constraints}\\
\end{align*}
The reason why this R1CS only contains a single contraint for the multiplication gate in the OR-circuit, while the general definition XXX requires two constraints, is that the second constraint in XXX only appears since the final addition gate is connected to an output node. In this case however the final addition gate from the OR-circuit is enforced in the left factor of the $I_{1}$ constraint. Something similar holds true for the negation circuit. 

During a proofer-phase, some public instance $I_5$ must be given. To compute a constructive proof for the statement of the associated languages with respect to instance $I_5$, a proofer has to find four boolean values $W_1$, $W_2$, $W_3$ and $W_4$, such that 
$$
\left( W_1 \vee W_2 \right) \wedge (W_3 \wedge \lnot W_4) = I_5
$$ 
holds true. In our case neither the circuit, nor the \texttt{PAPER} statement specifies how to find those values and it is a problem that any proofer has to solve outside of the circuit. This might or might not be true for other problems, too. In any case once the proofer found those values, they can execute the circuit to find a valid assignment. 

To give a concrete example let $I_1=1$ and assume $W_1=1$, $W_2=0$, $W_3=1$ and $W_4=0$. Since 
$\left( 1 \vee 0 \right) \wedge (1 \wedge \lnot 0) = 1$ those values satify the problem and we can use them to execute the circuit. We get 
\begin{align*}
W_5 & = W_1 \cdot (1- W_1) = 0\\
W_6 & = W_2 \cdot (1- W_2) = 0 \\
W_7 & = W_3 \cdot (1- W_3) = 0 \\
W_8 & = W_4 \cdot (1- W_4) = 0 \\
W_9 & = W_1\cdot W_2 = 0\\
W_{10} & = W_3 \cdot (1-W_4) = 1\\
I_1 & = (W_1 + W_2 - W_9) \cdot W_{10} = 1
\end{align*}
A constructive proof of knowledge of a witness for instance $I_1=1$ is therefore given by the tuple $P=(W_5,W_6,W_7,W_8,W_9,W_{10})=(0,0,0,0,0,1)$. 
\end{example}
\subsubsection{The Unsigned Integer Type} In computer science, an unsigned integer of size $N$, where $N$ is usually a power of two, is an atomic type that represents counting numbers in the range $0\ldots 2^N-1$ together with addition, subtraction and multiplication laws that are somewhat similar to the (semi) ring laws of natural numbers except for overflow and underflow effects. The associated type is usually written as $uN$ or $uIntN$.

On compuer hardware elements of the unsigned integer type $uIntN$ are commonly represented as $N$-tuples of bits, that is if $x : uIntN$ is of $uIntN$ type it is represented as
$$
x = (b_0,b_1,\ldots, b_{N-1})
$$
For suteable $N$ like $N=32$ or $N=64$, addition, subtraction and multiplication is realized in hardware by appropriate digital circuits like the binary adder oder the binary multiplier. 

To understand how unsigned integer types can be represented as algebraic circuits, basically two different approaches can be taken.

To understand the first approach, recall that addition and multiplication in a prime field $\F_p$ is equal to addition and multiplication of integers, as long as the sum or the product does not exceed the modulus $p$. It is therefore possible to represent the $uIntN$ type inside the basefield type, whenever $N$ is small enough. However care has to be taken to never overflow the modulus. It is also important to make sure that in subtraction the subtrahend is never larger then the minuent.

An advantage of this approach is that it is very efficient to represent elements of the uIntN type in this way, as they can be storred in a single element of the base field type. The diadvantage is that care must be taken to constrain the elements and to enforce that no overflow or underflow situations occure.

The second approach in conceptually cleaner but requires more space and constraints for addition and multiplication. Much like machines represents uInt's as binary tuples, this approach represents elements of uIntN types as $N$-typles $(b_0,b_1,\ldots, b_{N-1})$ of elements from the base field $\F$, such that each $b_j$ itself is of boolean type. All operations, like addition, multiplication, bit-shifts and so on, are then realized by addoptations of the digital circuits that implement these operations in hardware.

An advantage of this representation is that the number $N$ is independend of the modulus of the underlying prime field and the representation moreover works over arbitrary fields. It can therefore abstract over the field.


In what follows we will describe the second approach in more detail.


\paragraph{The uIntN Constraint System} In the approach we are taking in this section, elements of uIntN type are represented by $N$-tuples of field elements that are themself binary constraint. Declaring an element of uIntN type therefore means to declare $N$ elements of boolean type. We write this as 
\begin{center}
\digraph[scale=0.6]{UINTN}{
  forcelabels=true;
  center=true;
  splines=ortho;
  //nodesep= 2.0;
  n1 [shape=box, label="UINT_N"] ;
  n2 [shape=none, label="  "] ;
  n3 [shape=none, label="  "] ;
  n4 [shape=none, label="  "] ;
  n5 [shape=none, label="  "] ;
  n2 -> n1 ;
  n3 -> n1 ;
  n4 -> n1 [style=dashed, color=lightgrey] ;
  n5 -> n1 ;
}
\end{center}
To enfore an $N$-tuple of field elements $(b_0,\ldots,b_{N_1})$ to represent an element of UintN type we therefore need $N$ constraints 
\begin{align*}
E_0 \cdot (1-E_0) & = 0\\
E_1 \cdot (1-E_1) & = 0\\
\cdots &\\
E_{N-1} \cdot (1-E_{N-1}) & = 0\\
\end{align*}
\begin{example}
Consider the Uint4 type over the prime field $\F_{17}$. Since $2^4=16$, Uint4 can represent the numbers $0,\ldots, 15$ and it would be possible to interpret them as elements in $\F_{17}$. However addition 
\end{example} 
\paragraph{UintN Addition} Since we representat the unsigned integer type as an $N$-tuple of field elements that are boolean constraint, we can define addition in the same way as hardeare does. The way this is usually done is by first defining the \textit{full adder} circuit and then combining $N$ of this these circuits into a circuit that add to elements from the UintN type.

To understand the algebraic circuit for the $1$-bit full, recall that we already defined circuits for boolean algebra in the previous section. Abstracting over those circuits, a full adder circuit can then be defined as:
\begin{center}
\digraph[scale=0.4]{ONEBFULLADD}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  
  subgraph clusterin {
    nADD01 [shape=box, label="bx_j"] ;
    nADD02 [shape=box, label="by_j"] ;
    nADD03 [shape=box, label="c_(j-1)"] ;
    color = white ;
  }
  
  subgraph clustermid {
    nADD04 [shape=box, label="XOR"] ;
    nADD05 [shape=box, label="XOR"] ;
    nADD06 [shape=box, label="AND"] ;
    nADD07 [shape=box, label="AND"] ;
    nADD08 [shape=box, label="OR"] ;
    
    nADD04 -> {nADD05, nADD06} ;
    nADD06 -> nADD08 ;
    nADD07 -> nADD08 ;
    
    color = white ;
  }
  
  subgraph clusterout {
    nADD09 [shape=box, label="bz_j"] ;
    nADD010 [shape=box, label="c_j"] ;
    color = white ;
  }
  
  nADD01 -> {nADD04, nADD07} ;
  nADD02 -> {nADD04, nADD07} ;
  nADD03 -> {nADD05, nADD06} ;
  nADD05 -> nADD09 ;
  nADD08 -> nADD010 ; 
}
\end{center}
In this circuit the output $bz_j$ is the result of the binary input $bx_j$ and $by_j$, where $bx_j$ is the $j$-th bit of the binary representation of the first summand and $by_j$ is the $j$-th bit of the binary representation of the second summand. The output $c_j$ is the carry bit of the addition and the input $c_{j-1}$ is is the carry bit which is supposed to be either $0$ for $j=0$ or the carry bit output of the previous full adder circiut. Abstacting the $1$-bit adder, we write:
\begin{center}
\digraph[scale=0.6]{BADDMETA}{
  forcelabels=true;
  center=true;
  splines=ortho;
  //nodesep= 2.0;
  n1 [shape=box, label="FULLADD"] ;
  n2 [shape=none, label="bx_j"] ;
  n3 [shape=none, label="by_j"] ;
  n4 [shape=none, label="c_(j-1)"] ;
  n5 [shape=none, label="bz_j"] ;
  n6 [shape=none, label="c_j"] ;
  n2 -> n1 ;
  n3 -> n1 ;
  n4 -> n1 ;
  n1 -> {n5, n6} ;
}
\end{center}
With a circuit definition of the $1$-bit full adder at hand, addition of two uIntN type elements can then be defined as
\begin{center}
\digraph[scale=0.4]{UINTADD}{
  forcelabels=true;
  center=true;
  splines=ortho;
  //nodesep= 2.0;
  
  subgraph clusterin0 {
    nADD01 [shape=box, label="FULLADD"] ;
    nADD02 [shape=none, label="bx_0"] ;
    nADD03 [shape=none, label="by_0"] ;
    nADD05 [shape=none, label="bz_0"] ;
    nADD02 -> nADD01 ;
    nADD03 -> nADD01 ;
    nADD01 -> nADD05 ;
    color = white ;
  }
  
  subgraph clusterin1 {
    nADD11 [shape=box, label="FULLADD"] ;
    nADD12 [shape=none, label="bx_1"] ;
    nADD13 [shape=none, label="by_1"] ;
    //nADD14 [shape=none, label="c_0"] ;
    nADD15 [shape=none, label="bz_1"] ;
    nADD12 -> nADD11 ;
    nADD13 -> nADD11 ;
    //nADD14 -> nADD11 ;
    nADD11 -> nADD15 ;
    color = white ;
  }

  subgraph clusterin2 {
    nADD21 [shape=box, label="FULLADD", color=lightgray] ;
    nADD22 [shape=none, label="bx_j", color=lightgray] ;
    nADD23 [shape=none, label="by_j", color=lightgray] ;
    //nADD24 [shape=none, label="c_(j-1)", color=lightgray] ;
    nADD25 [shape=none, label="bz_j", color=lightgray] ;
    nADD22 -> nADD21 [color=lightgray];
    nADD23 -> nADD21 [color=lightgray];
    //nADD24 -> nADD21 ;
    nADD21 -> nADD25 [color=lightgray] ;
    color = white ;
  }
  
  subgraph clusterinN {
    nADDN1 [shape=box, label="FULLADD"] ;
    nADDN2 [shape=none, label="bx_(N-1)"] ;
    nADDN3 [shape=none, label="by_(N-1)"] ;
    //nADDN4 [shape=none, label="c_(N-2)"] ;
    nADDN5 [shape=none, label="bz_(N-1)"] ;
    nADDN2 -> nADDN1 ;
    nADDN3 -> nADDN1 ;
    //nADDN4 -> nADDN1 ;
    nADDN1 -> nADDN5
    color = white ;
  }
  
  nADD04 [shape=none, label="0"] ;
  nADD04 -> nADD01 ;
  nADD01 -> nADD11 ;
  nADD11 -> nADD21 [style=dashed, color=lightgrey] ;
  nADD21 -> nADDN1  [style=dashed, color=lightgrey] ;
  nADDN6 [shape=none, label="c_out"] ;
  nADDN1 -> nADDN6 ;
  
}
\end{center}
Depending on how the output carry bit is handled we get different definition of addition in this type. One way would be to enforce it to be zero. This way addition in the circuit is only possible if the sum does not exceed $2^N-1$. On the other hand if the carry bit is unconstraint, then the resulting addition is equivalent to modulo $2^N$ arithmetics. Good  compilers should therefore always describe explicitly how exactly their implementation of the uintN type behaves, such that users don't build their system on false assumptions. 

The associated constraint system consists of XXX constraints, including the boolean constraints of the representing bits
\paragraph{The Boolean Operators} In implementations it is often necesarry to execute boolean operations like $ans$, $or$, or $xor$ on elements of the uInt type. Fortunately this easily done by simply applying those operatons to every bit seperately as shown in XXX.  
\begin{exercise}
Let $k$ be a counting number with $k<N$. Define circuits and associated R1CS for the left and righr bishift operators $x<<k$ as well as $x>>k$ for the uint type. 
\end{exercise}
\begin{exercise}
Define the multiplication circuits for the uintN type.
\end{exercise}
\begin{exercise} Let $N=4$ be fixed and consider the finite field $\F_{13}$ from example XXX. The following pseudo code describes a high level circuit description in a VERILOG like style. Transform the pseudo code into a circuit and then derive the associated R1CS. 
\begin{lstlisting}
module mask_merge(N) (
	input (public) a : Uint_N ;
	input (public) b : Uint_N ;
	input (public) mask : Uint_N ;
	output (public) r : Uint_N ;

	begin
		r == a xor ((a xor b) & mask) ;
	end ;
)
\end{lstlisting}
Let $L_{mask\_merge}$ be the language defined by the R1CS of the circuit. Provide a knowledge proof in $L_{mask\_merge}$ for the instance $I=(I_a, I_b, I_{mask}, I_r) = (14, 5, 10, 4)$. Also show that there is no knowledge proof in $L_{mask\_merge}$ for the instance $(11, 6, 10, 7)$.
\end{exercise}
\subsubsection{Arrays}

\subsection{Control Flow}
\subsubsection{The Conditional Assignment} Implementing complex control flow in circuits, it is often necessary to have a way for conditional assignment of values or computational output to variables.

One way to realize this in more common programming languages is by the conditional ternary operator $?:$, that branches the control flow of a program according to some condition and then assigns the output of the computational branch to some variable. A common way to write this is as
\begin{lstlisting}
	variable = condition ? value_if_true : value_if_false  
\end{lstlisting}
where \textsc{condition} is a boolean expression and \textsc{value\_if\_true} as well as \textsc{value\_if\_false} are expressions that evaluate to the same type as \textsc{variable}.

In programming languages like Rust another way to write the conditional assignment operator that is more familiar to many programmers is given by 
\begin{lstlisting}
	variable = if condition { value_if_true } else { value_if_false } 
\end{lstlisting}
One particular property of this operator is that the expression \textsc{value\_if\_true} is only evaluated if \textsc{condition} evaluates to true and the expression \textsc{value\_if\_false} is only evaluated if \textsc{condition} evaluates to false. In fact computer programs would soon become very inefficient if the operator would evaluate both expressions regardless of the value of \textsc{condition}.

If drop the requirement that only one branch of the conditional operator is executed, we can implement it in a simple way as a circuit. To see that observe that if $b$, $c$ and $d$ are values from a finite field, such that $b$ is boolean constraint (XXX), we can use the following equation to enforce a field element $x$ to be the result of the conditional assignment operator: 
\begin{equation}
x = b\cdot c + (1-b)\cdot d
\end{equation}
Flattening this equation into an algebraic circuit gives
\begin{center}
\digraph[scale=0.4]{CONDASSIGN}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;

  n1 [shape=box, label="b"]
  n2 [shape=box, label="c"]
  n3 [shape=box, label="d"]
  n4 [shape=box, label="b ? c : d"]
  n5 [shape=box, label="-1"]
  n6 [shape=box, label="1"]
  n7 [shape=box, label="*"]
  n8 [shape=box, label="*"]
  n9 [shape=box, label="*"]
  n10 [shape=box, label="+"]
  n11 [shape=box, label="+"]
 
  n1 -> n7 [taillabel= "E_1  "] ;
  n1 -> n8 [taillabel= "E_1 "] ;
  n2 -> n7 [xlabel= "E_2"] ;
  n3 -> n9 [xlabel= "E_4"] ;
  n5 -> n8 ;
  n6 -> n10 ;
  n7 -> n11 [xlabel= "E_3  "] ;
  n8 -> n10 ;
  n9 -> n11 [xlabel= "E_5"] ;
  n10 -> n9 ;
  n11 -> n4 [xlabel= "E_6  "] ;
}
\end{center}
Note that in order to compute a valid assignment to this circuit, both values for $W_?$ and $W_?$ are necessary. If the inputs to thoses edges are circuits themself, both circuits needs valid assignments. As a consequence this implementation of the conditional assigment opperator has to execute alll branches of all circuits, which is very different from the execution of common computer programs. 

Starting at this circuit we can use the general tenchnique from XXX to derive its associated rank-1 constraint system. We get
\begin{align*}
E_1 \cdot E_2 & = E_3 \\
(1 - E_1) \cdot E_4 & = E_5 \\
(E_3 + E_5)\cdot 1 &= E_6
\end{align*}
\begin{example} Let $N=4$ be fixed.
\begin{lstlisting}
module conditional_bit_set(N) (
	input (public) c : BOOL ;
	input (public) mask : Uint_N ;
	input (public) w : Uint_N ;
	output (public) r : Uint_N ;

	begin
		r == if c { w or mask } else { w and not mask } ;
	end ;
)
\end{lstlisting}
\end{example}

% NOTE: ZK-Podcast with Alex Özdemir for the proper branching thing in version 2 of the book.

\subsubsection{Loops} Circuits and R1CS are not general enough to express arbitrary computations, but bounded computations only. As a consequence it is not possible to represent unbounded loops like $while TRUE do {}$ in algebraic circuits or rank-1 constraints systems. This can be easily seen since circuits are acyclic graphs and hence unbounded loops would require circuits of unbounded sizes. However bounded loops are expressible, simply by enrolling the loop. 

\begin{example}
\begin{lstlisting}
module counting_bits(N) (
for (c = 0; v; v >>= 1)
{
  c += v & 1;
}

	begin
		r == a xor ((a xor b) & mask) ;
	end ;
)
\end{lstlisting}
\end{example}

\subsection{Gadgets}
\subsubsection{Binary representations}
If the underlying field has a modulus $p$, such that $2^N-1 < p$, then there is a standard way to transform field elements $x\in \F_p$ of size $x<2^N$ into a UIntN bit representation and vice versa.

To make the UintN type more human readable, compilers might introduce some synthactic suggar and outside of the circuit converging back and forth between the base $2$ and base $10$ representation of the UintN type. A standard way to do it is as follows: 

Consider a base $10$ representation $x$ of a UintN type. Then its binary representation 
$(b_0,\ldots,b_{N-1})$ can be computed by 
\begin{lstlisting}
input x : UINT_N ; 
output b[N] : BOOL ; 
var lc1=0;
var e2=1;
for (var i = 0; i < N; i++) {
    b[i] <-- (in >> i) & 1;
    lc1 += b[i] * e2;
    e2 = e2+e2;
}
\end{lstlisting}
This computation is of course done outside of the circuit as a high level inteface for human friendly input. On the other hand if the internal representation $(b_1,\ldots, b_{N-1})$ is given, then the human readable base $10$ representation is given by:
\begin{lstlisting}
input b[N] : BOOL ; 
output x : UINT_N ; 
var lc1=0;
var e2=1;
for (var i = 0; i < N; i++) {
    b[i] <-- (in >> i) & 1;
    lc1 += b[i] * e2;
    e2 = e2+e2;
}
\end{lstlisting}



In computations like scalar multiplication of elliptic curve points its is often necessary to use a binary representation of elements from the base field type. It is therefore necesaary to have a way to transform field elements into their binary representation and vice versa in circuits.

To derive such a circuit over a prime field $\F_p$, let $m=|p_{base_2}|$ be the smallest number of bits necessary to represent the prime modulus $p$ itself. Then a bitstring $(b_0,\ldots,b_{m-1})\in \{0,1\}^m$ is a binary representation of a field element $x\in\F_p$, if and only if
$$
x = b_0\cdot 2^0 + b_1\cdot 2^1 + \ldots + b_m\cdot 2^{m-1}
$$ 
In this expression, addition and exponentiation is considered to be executed in $\F_p$, which is well defined, since all terms $2^j$ for $0\leq j \leq m$ are elements of $\F_p$. Note however that in contrast to the binary representation of counting numbers $n\in\N$, this representation is not unique in prime fields for odd prime numbers. 
\begin{example} Considering the prime field $\F_{13}$. To compute binary representations of elements from that field, we start with the binary representation of prime modulus $13$, which is $13_{base_2} = (1,0,1,1)$ since 
$13= 1\cdot 2^0 + 0\cdot 2^1 + 1\cdot 2^2 + 1\cdot 2^3$. So $m=4$ and we need up to $4$ bits to represent any element $x\in\F_{13}$.

To see that binary representations are not unique in general, consider the element $2\in \F_{13}$. It has the binary representations $2_{base_2}=(0,1,0,0)$ as well as $2_{base_2}=(1,1,1,1)$, since in $\F_{13}$ we have
$$
2 = \begin{cases}
0\cdot 2^0 + 1\cdot 2^1 + 0\cdot 2^2 + 0\cdot 2^3\\
1\cdot 2^0 + 1\cdot 2^1 + 1\cdot 2^2 + 1\cdot 2^3
\end{cases}
$$
\end{example}
Considering that the underlying prime field is fixed and the most significant bit of the prime modulus is $m$, the following circuit flattens equation XXX, assuming all inputs $b_1$, $\ldots$, $b_m$ are restricted to be either $0$ or $1$:
\begin{center}
\digraph[scale=0.3]{BINARYREP}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;

  subgraph cluster0 {
    n1 [shape=box, label="b_0"] ;
    n2 [shape=box, label="2^0"] ;
    n3 [label="*"] ;

    n1 -> n3 ;
    n2 -> n3  [xlabel="I_0"] ;
    color=white ;
  }

  subgraph cluster1 {
    n4 [shape=box, label="b_1"] ;
    n5 [shape=box, label="2^1"] ;
    n6 [label="*"] ;

    n4 -> n6 ;
    n5 -> n6  [xlabel="I_1  "] ;
    color=white ;
  }

  subgraph cluster2 {
    n7 [shape=box, label="b_2"] ;
    n8 [shape=box, label="2^2"] ;
    n9 [label="*"] ;

    n7 -> n9 ;
    n8 -> n9 [xlabel="I_2  "];
    color=white ;
  }

  subgraph cluster3 {
    n10 [shape=box, label="...", color=lightgrey] ;
    color=white ;
  }

  subgraph cluster4 {
    n11 [shape=box, label="b_(m-1)"] ;
    n12 [shape=box, label="2^(m-1)"] ;
    n13 [label="*"] ;

    n11 -> n13 ;
    n12 -> n13  [xlabel="I_(m-1)  "] ;
    color=white ;
  }

  subgraph cluster5 {
    n18 [shape=box, label="x"] ;
    n19 [shape=box, label="-1"] ;
    n20 [label="*"] ;

    n18 -> n20  [xlabel="I_m"] ;
    n19 -> n20 ;
    color=white ;
  }

  n14 [label="+"] ;
  n15 [label="+"] ;
  n16 [label="+", color=lightgrey] ;
  n17 [label="+"] ;
  n21 [label="+"] ;
  n22 [shape=0, label="0"] ;
  n3 -> n14 ;
  n6 -> n14 ; 
  n14 -> n15 ;
  n9 -> n15 ;
  n10 -> n16 [style=dashed, color=lightgrey] ;
  n15 -> n16 [style=dashed, color=lightgrey] ;
  n13 -> n17 ;
  n16 -> n17 [style=dashed, color=lightgrey] ;
  n20 -> n21 ;
  n17 -> n21 ;
  n21 -> n22  [xlabel="W_1=0  "] ;
}
\end{center}
Applying the general transformation rule into rank-1 constraint systems, we see that we actually only need a single constraint to enforce a binary representation of any field element. We get 
$$
(b_0\cdot 2^0 + b_1\cdot 2^1 + b_2\cdot 2^2 + \ldots + b_{m-1}\cdot 2^{m-1} -x)\cdot 1 = 0
$$
In designing more complex circuits from simple ones it is often conceptually as well as visually useful to collaps circuits into simple representative description. To do so, we write 
\begin{center}
\digraph[scale=0.6]{BINREPMETA}{
  forcelabels=true;
  center=true;
  splines=ortho;
  //<nodesep= 2.0;
  n1 [shape=box, label="BASE2"] ;
  n2 [shape=none, label="  "] ;
  n3 [shape=none, label="  "] ;
  n4 [shape=none, label="  "] ;
  n5 [shape=none, label="  "] ;
  n6 [shape=none, label="x"] ;
  n2 -> n1 ;
  n3 -> n1 ;
  n4 -> n1 [style=dashed];
  n5 -> n1 ;
  n6 -> n1 ;
}
\end{center}
indicating that the BASE2 circuit takes $m$ input, has no output and constraints the $x$ input to be the BLABLABLA
\begin{example} Considering the prime field $\F_{13}$, we want to enforce the binary representation of $7\in \F_{13}$. We know $m=4$ from example XX and we have to enforce a $4$-bit representation for $7$, which is $(1,1,1,0)$, since $7= 1\cdot 2^0 + 1\cdot 2^1 + 1\cdot 2^2 + 0\cdot 2^3$.

A valid circuit assignment is therefore given by $(I_0,I_1,I_2,I_3,I_4)=(1,1,1,0,7)$ and indeed we satify the required 5 constraints including the $4$ boolean constraints for $I_0$, $\ldots$, $I_3$ as 
\begin{align*}
1\cdot (1-1) &= 0 & \text{// boolean constraints}\\
1\cdot (1-1) &= 0 \\
1\cdot (1-1) &= 0 \\
0\cdot (1-0) &= 0  \\
(1 + 2 + 4 + 0 -7)\cdot 1 &= 0  & \text{// binary rep. constraint}
\end{align*}
\end{example}

\subsubsection{Range Proofs}
$x>5$...


\subsection{Cryptographic Primitives}
\subsubsection{Twisted Edwards curves}
Sometimes it required to do elliptic curve cryptography "inside of a circuit". This means that we have to implement the algebraic operations (addition, scalar multiplication) of an elliptic curve as a R1CS. To do this efficiently the curve that we want to implement must be defined over the same base field as the field that is used in the R1CS. 

% implmentations https://github.com/iden3/circomlib/blob/master/circuits/babyjub.circom

\begin{example}
So for example when we consider an R1CS over the field $\F_{13}$ as we did in example XXX, then we need a curve that is also defined over $\F_{13}$. Moreover it is advantegous to use a (twisted) Edwards curve inside a circuit, as the addition law contains no branching (See XXX). As we have seen in XXX our Baby-Jubjub curve is an Edwards curve defined over $\F_{13}$. So it is well suited for elliptic curve cryptography in our pend and paper examples
\end{example}

\paragraph{Twisted Edwards curves constraints} As we have seen in XXX, an Edwards curve over a finite field $F$ is the set of all pairs of points $(x,y)\in \F\times \F$, such that $x$ and $y$ satisfy the equation $a\cdot x^2+y^2= 1+d\cdot x^2y^2$. 

We can interpret this equation as a constraint on $x$ and $y$ and rewrite it as a R1CS by applying the flattenin technique from XXX.
$$
\begin{array}{lcr}
x \cdot x &=& x\_sq\\
y \cdot y &=& y\_sq\\
x\_sq \cdot y\_sq &=& xy\_sq\\
(a\cdot x\_sq+y\_sq)\cdot 1 &=& 1+d\cdot xy\_sq
\end{array}
$$
So we have the statement $w=(1,x,y,x\_sq, y\_sq, xy\_sq)$ and we need 4 constraints to enforce that $x$ and $y$ are points on the Edwards curve $x^2+y^2= 1+d\cdot x^2y^2$. Writing the constraint system in matrix form, we get:
\begingroup
    \fontsize{9pt}{9pt}\selectfont
$$
\begin{pmatrix}
0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & a & 1 & 0 
\end{pmatrix} \begin{pmatrix} 1 \\ x \\ y \\ x\_sq \\ y\_sq \\ xy\_sq \end{pmatrix}\odot
\begin{pmatrix}
0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 \\
1 & 0 & 0 & 0 & 0 & 0 
\end{pmatrix}  \begin{pmatrix} 1 \\ x \\ y \\ x\_sq \\ y\_sq \\ xy\_sq \end{pmatrix} =
\begin{pmatrix}
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 0 & d 
\end{pmatrix} \begin{pmatrix} 1 \\ x \\ y \\ x\_sq \\ y\_sq \\ xy\_sq \end{pmatrix}
$$
\endgroup
EXERCISE: WRITE THE R1CS FOR WEIERSTRASS CURVE POINTS 
\begin{example}[Baby-JubJub]
Considering our pen and paper Baby JubJub curve over from XXX, we know that the curve is defined over $\F_{13}$ and that $(11,9)$ is a curve point, while $(2,3)$ is not a curve point. 

Starting with $(11,9)$, we can compute the statement $w=(1,11,9,4,3,12)$. Substituting this into the constraints we get
$$
\begin{array}{lcr}
11 \cdot 11 &=& 4\\
9 \cdot 9 &=& 3\\
4 \cdot 3 &=& 12\\
(1\cdot 4+3)\cdot 1 &=& 1+7\cdot 12
\end{array}
$$
which is true in $\F_{13}$. So our statement is indeed a valid assignment to the twisted Edwards curve constraining system.

Now considering the non valid point $(2,3)$, we can still come up with some kind of statement $w$ that will satisfy some of the constraints. But fixing $x=2$ and $y=3$, we can never satisfy all constraints. For example $w=(1,2,3,4,9,10)$ will satisfy the first three constraints, but the last constrain can not be satisfied. Or $w=(1,2,3,4,3,12)$ will satisfy the first and the last constrain, but not the others.
\end{example}
\paragraph{Twisted Edwards curves addition} As we have seen in XXX one the major advantages of working with (twisted) Edwards curves is the existence of an addition law, that contains no branching and is valid for all curve points. Moreover the neutral element is not "at infinity" but the actual curve poin $(0,1)$.

As we know from XXX, give two points $(x_1,y_1)$ and $(x_2,y_2)$ on a twisted Edwards curve their sum is given by
$$
(x_3,y_3) = \left(\frac{x_1y_2+y_1x_2}{1+d\cdot x_1x_2y_1y_2}, \frac{y_1y_2-a\cdot x_1x_2}{1-d\cdot x_1x_2y_1y_2}\right)
$$
% https://z.cash/technology/jubjub/
We can use the division circuit from XXX to flatten this equation into an algeraic circuit. Inputs to the circuit are then the two curve points $(x_1,y_1)$ abd $(x_2,y_2)$ as well as the the two denominators $denum_1 = 1+d\cdot x_1x_2y_1y_2$ as well as $denum_2= 1-d\cdot x_1x_2y_1y_2$. We get
\begin{center}
\digraph[scale=0.6]{EDWARDSADD}{
  forcelabels=true;
  center=true;
  splines=ortho;
  //nodesep= 2.0;
  
  subgraph clusterin {
    n1 [shape=box, label="x_1"] ;
    n2 [shape=box, label="x_2"] ;
    n3 [shape=box, label="y_1"] ;
    n4 [shape=box, label="y_2"] ;
      
    n22 [shape=box, label="denom_1"] ;
    n23 [shape=box, label="denom_2"] ;
  
    color=white ;
  }
  
  subgraph clusterout {
    n29 [shape=box, label="x_3"] ;
    n30 [shape=box, label="y_3"] ;
  
    color=white ;
  }

    n5 [shape=box, label="a"] ;
    n6 [shape=box, label="d"] ;
    n7 [shape=box, label="1"] ;
    n8 [shape=box, label="-1"] ;
    
    n9 [label="*"] ; // x_1*y_2
    n10 [label="*"] ; // x_1*x_2
    n11 [label="*"] ; // y_1*x_2
    n12 [label="*"] ; // y_1*y_2
    n13 [label="*"] ; // a*(x_1*x_2)
    n14 [label="*"] ; // -a*(x_1*x_2)
    n15 [label="+"] ; // x_1*y_2 + y_1*x_2
    n16 [label="+"] ; // y_1*y_2 - a*x_1*x_2
    n17 [label="*"] ; // (x_1*x_2)*(y_1*y_2)
    n18 [label="*"] ; // d*(x_1*x_2)*(y_1*y_2)
    n19 [label="*"] ; // -d*(x_1*x_2)*(y_1*y_2)
    n20 [label="+"] ; // 1 + d*(x_1*x_2)*(y_1*y_2)
    n21 [label="+"] ; // 1 - d*(x_1*x_2)*(y_1*y_2)
    
    n24 [label="*"] ; // (1 + d*(x_1*x_2)*(y_1*y_2))*denom_1 =1 
    n25 [label="*"] ; // (1 - d*(x_1*x_2)*(y_1*y_2))*denom_2 =1 
    n26 [shape=box, label="1"] ;
    n27 [label="*"] ; // denom_1*(x_1*y_2 + y_1*x_2) 
    n28 [label="*"] ; // denom_2*(y_1*y_2 - a*x_1*x_2) 
    
    n1 -> n9 [headlabel=" E_1"];
    n1 -> n10 [taillabel="E_1"];
    n2 -> {n10, n11} [taillabel="E_2"];
    n3 -> n11 [headlabel=" E_3"];
    n3 -> n12 [taillabel="E_3"];
    n4 -> n9 [taillabel="E_4"];
    n4 -> n12 [headlabel="  E_4"];
    n5 -> n13 ;
    n6 -> n18 ;
    n7 -> {n20, n21}
    n8 -> {n14, n19} ;
    n9 -> n15 [headlabel=" E_7"] ;
    n10 -> n13 [xlabel="E_8"] ;
    n10 -> n17 [xlabel="E_8"] ;
    n11 -> n15 [xlabel="E_9"] ;
    n12 -> n16 [taillabel="E_10 "] ;  
    n12 -> n17 [xlabel="  E_10"] ;   
    n13 -> n14 ;
    n14 -> n16 ;
    n15 -> n27 ;
    n16 -> n28 ; 
    n17 -> n18 [xlabel="E_11"] ;
    n18 -> {n19, n20} ;
    n19 -> n21 ;
    n20 -> n24 ;
    n21 -> n25 ;
    n22 -> {n24, n27} [xlabel="E_5"] ;
    n23 -> {n25, n28}  [xlabel="E_6"] ;
    n24 -> n26 [xlabel="E_12=1"] ;
    n25 -> n26 [xlabel="E_13=1"] ;
    
    n27 -> n29 [xlabel="E_14"] ;
    n28 -> n30 [xlabel="E_15"] ;
    
}
\end{center}
Using the general technique from XXX to derive the associated rank-1 constraint system, we get the following result:
\begin{align*}
E_1 \cdot E_4 & = E_7 \\
E_1 \cdot E_2 & = E_8 \\
E_2 \cdot E_3 & = E_9 \\
E_3 \cdot E_4 & = E_{10} \\
E_8 \cdot E_{10} & = E_{11} \\
E_5 \cdot (1+ d\cdot E_{11}) & = 1 \\
E_6 \cdot (1 - d\cdot E_{11}) & = 1 \\
E_5 \cdot (E_9 + E_7) & = E_{14} \\
E_6 \cdot (E_{10} - a\cdot E_8) & = E_{15}
\end{align*}

So we have the statement $w=(1,x_1,y_1,x_2,y_2,x_3,y_3,x_{12},y_{12},xy_{12},yx_{12},xy_{1212})$ and we need 7 constraints to enforce that $(x_1,y_1)+(x_2,y_2)=(x_3,y_3)$ 
\begin{example}[Baby-JubJub]
Considering our pen and paper Baby JubJub curve over from XXX. We recall from XXX that $(11,9)$ is a generator for the large prime order subgroup. We therefor already know from XXX that
$(11,9) + (7,8) = (11,9) + [3](11,9) = [4](11,9) = (2,9)$. So we compute a valid statement as 
$w=(1,11,9,7,8,2,9,12,7,10,11,6)$. Indeed
$$
\begin{array}{lcl}
11\cdot 7 &=& 12\\
9\cdot 8 &=& 7\\
11\cdot 8 &=& 10\\
9\cdot 7 &=& 11\\
10\cdot 11 &=& 6\\
2\cdot (1+7\cdot 6) &=& 10 + 11\\
9\cdot (1-7\cdot 6) &=& 7 -1\cdot 12
\end{array}
$$
\end{example}
There are optimizations for this using only 6 constraints, available:
% https://github.com/filecoin-project/zexe/blob/master/snark-gadgets/src/groups/curves/twisted_edwards/mod.rs#L129

\paragraph{Twisted Edwards curves inversion} Similar to elliptic curves in Weierstrass form, inversion is cheap on Edwards curve as the negative of a curve point $-(x,y)$ is given by $(-x,y)$. So a curve point $(x_2,y_2)$ is the additive inverse of another curve point $(x_1,y_1)$ precisely if the equation $(x_1,y_1) = (-x_2,y_2)$ holds. We can write this as
$$
\begin{array}{lcl}
x_1 \cdot 1 &=& -x_2 \\
y_1 \cdot 1 &=& y_2
\end{array}
$$
We therefor have a statement of the form $w=(1,x_1,y_1,x_2,y_2)$ and can write the constraints into a matrix equation as
$$
\begin{pmatrix}
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0
\end{pmatrix} \begin{pmatrix} 1 \\ x_1 \\ y_1 \\ x_2 \\ y_2 \end{pmatrix}\odot
\begin{pmatrix}
1 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 0 & 0
\end{pmatrix} \begin{pmatrix} 1 \\ x_1 \\ y_1 \\ x_2 \\ y_2 \end{pmatrix} =
\begin{pmatrix}
0 & 0 & 0 & -1 & 0\\
0 & 0 & 0 & 0 & 1
\end{pmatrix} \begin{pmatrix} 1 \\ x_1 \\ y_1 \\ x_2 \\ y_2 \end{pmatrix}
$$

In addition we need the following constraints:
$$
\begin{array}{lcl}
x_1 \cdot 1 &=& -x_2 \\
y_1 \cdot 1 &=& y_2
\end{array}
$$

\paragraph{Twisted Edwards curves scalar multiplication} 
% original circuit is here https://iden3-docs.readthedocs.io/en/latest/_downloads/33717d75ab84e11313cc0d8a090b636f/Baby-Jubjub.pdf

Although there are highly optimzed R1CS implementations for scal multiplication on elliptic curves, the basic idea is somewhat simple: Given an elliptic curve $E/\F_r$, a scalar $x\in \F_r$ with binary representation $(b_0,\ldots,b_m)$ and a curve point $P\in E/\F_r$, the scalar multiplication $[x]P$ can be written as
$$
[x]P = [b_0]P + [b_1]([2]P) + [b_2]([4]P) + \ldots + [b_m]([2^m] P)
$$
and since $b_j$ is either $0$ or $1$, $[b_j](kP)$ is either the neutral element of the curve or $[2^j]P$. However $[2^j]P$ can be computed inductively by curve point doubling, since $[2^j]P= [2]([2^{j-1}]P)$.

So scalar multiplication can be reduced to a loop of length $m$, where the original curve point is repeadedly douled and added to the result, whenever the appropriate bit in the scalar is equal to one.

So to enforce that a curve point $(x_2,y_2)$ is the scalar product $[k](x_1,y_1)$ of a scalar $x\in F_r$ and a curve point $(x_1,y_1)$, we need an R1CS the defines point doubling on the curve (XXX) and an R1CS that enforces the binary representation of $x$ (XXX). 

In case of twisted Edwards curve, we can use ordinary addition for doubling, as the constraints works for both cases (doublin is addition, where both arguments are equal). Moreover $[b](x,y)=(b\cdot x, b\cdot y)$ for boolean $b$. Hence flattening equation XXX gives
$$
\begin{array}{lclr}
b_0\cdot x_1 &=& x_{0,1} & // [b_0]P\\
b_0\cdot y_1 &=& y_{0,1}\\

\end{array}
$$
In addition we need to constrain $(b_0,\ldots, b_N)$ to be the binary representation of $x$ and we need to constrain each $b_j$ to be boolean.

As we can see a R1CS for scalar multiplication utilizes many R1CS that we have introduced before. For efficiency and readability it is therefore useful to apply the concept of a gadget (XXX). A pseudocode method to derive the associated R1CS could look like this:

%\begin{algorithmic}
%\Require $m$ Bitlength of modulus
%\Statement $w \gets [x,b[m],mid[m]]$
%\State $tmp \gets 0$
%\For{$j\gets 1,\ldots, m$}
%	\State \textbf{Constrain:} $b[j]\cdot (1-b[j]) == 0$
%	\State \textbf{Constrain:} $b[j] \cdot 2^j == mid[j]$
%	\State $tmp = tmp + mid[j]$
%\EndFor
%\State \textbf{Constrain:} $tmp \cdot 1 == x$
%\end{algorithmic}

%\begin{codebox}
%\Procname{$\proc{Insertion-Sort}(A)$}
%\li \For $j \gets 2$ \To $\id{length}[A]$
%\li     \Do$\id{key} \gets A[j]$
%\li         \Comment Insert $A[j]$ into the sorted sequence $A[1 \twodots j-1]$.
%\li         $i \gets j-1$\li         \While $i > 0$ and $A[i] > \id{key}$
%\li             \Do$A[i+1] \gets A[i]$
%\li                 $i \gets i-1$\End
%\li         $A[i+1] \gets \id{key}$\End
%\end{codebox}

\subsubsection{A Simple Pen and Paper Compiler Example}
% Set membership proof?


\subsection{Outlook on Real World Implementations}
many circuits can be found here:
% https://github.com/iden3/circomlib

Use the description of Özdemir in Ana's podcast. 

